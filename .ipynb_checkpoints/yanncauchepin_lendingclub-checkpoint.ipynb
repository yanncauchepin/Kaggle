{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a499894c",
   "metadata": {},
   "source": [
    "## Yann Cauchepin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfce03",
   "metadata": {},
   "source": [
    "Hi, here is my documented jupyter notebook which respond to the test request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1b09e",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Before even running the following script, please process by:\n",
    "\n",
    "- [ ] Installing the interested librairies. You can comment the next script to not bide your time.\n",
    "\n",
    "- [ ] Replacing dataset path toward your local repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a923e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "# !pip install tqdm\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install pyspark\n",
    "# !pip install catboost\n",
    "# !pip install shap\n",
    "# !pip install pingouin\n",
    "# !pip install seaborn\n",
    "# !pip install torch\n",
    "# !pip install captum\n",
    "# !pip install sklearn\n",
    "# !pip install mapie\n",
    "# !pip install scikit-optimize\n",
    "# !pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b006539",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"/media/yanncauchepin/ExternalDisk/Datasets/MachineLearningTables/lending_club/LCDataDictionary.xlsx\"\n",
    "data_path = \"/media/yanncauchepin/ExternalDisk/Datasets/MachineLearningTables/lending_club/Loan_status_2007-2020Q3.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939e91c",
   "metadata": {},
   "source": [
    "Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c14c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957f17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(metadata_path, index_col=0)\n",
    "metadata = metadata.iloc[:-2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ddf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/22 09:08:25 WARN Utils: Your hostname, yanncauchepincomputer resolves to a loopback address: 127.0.1.1; using 192.168.43.208 instead (on interface wlp2s0)\n",
      "24/06/22 09:08:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/22 09:08:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 2:=====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 2925493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:================================================>        (12 + 2) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LendingClubDataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_spark = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "print(f\"Number of data: {df_spark.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4751cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata features: 151\n",
      "Data features: 142\n",
      "Unknown data features: ['_c0', 'verification_status_joint', 'total_rev_hi_lim', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med'] (14)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata features: {len(metadata.index)}\")\n",
    "print(f\"Data features: {len(df_spark.columns)}\")\n",
    "\n",
    "outer_features = [feature for feature in df_spark.columns if feature not in metadata.index]\n",
    "\n",
    "print(f\"Unknown data features: {outer_features} ({len(outer_features)})\")\n",
    "df_spark = df_spark.drop(*outer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8175f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['grade', 'sub_grade']\n",
    "df_spark = df_spark.drop(*features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83763e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [feature for feature in df_spark.columns if feature != 'loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3876cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distincts values: 12 - 4.10e-06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|         loan_status|  count|\n",
      "+--------------------+-------+\n",
      "|          Fully Paid|1497783|\n",
      "|                NULL|      1|\n",
      "|     In Grace Period|  10028|\n",
      "|Does not meet the...|   1988|\n",
      "|         Charged Off| 362547|\n",
      "|  Late (31-120 days)|  16154|\n",
      "|             Current|1031016|\n",
      "|Does not meet the...|    761|\n",
      "|   Late (16-30 days)|   2719|\n",
      "|             Default|    433|\n",
      "|              Issued|   2062|\n",
      "|            Oct-2015|      1|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "value_counts = df_spark.groupBy('loan_status').count()\n",
    "value_rate = value_counts.count() / df_spark.count()\n",
    "print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b9bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mapping = {\n",
    "    'Fully Paid': 0,\n",
    "    'Charged Off': 1,\n",
    "    'Current': np.nan,\n",
    "    'Late (31-120 days)': np.nan,\n",
    "    'In Grace Period': np.nan,\n",
    "    'Late (16-30 days)': np.nan,\n",
    "    'Issued': np.nan,\n",
    "    'Does not meet the credit policy. Status:Fully Paid': np.nan,\n",
    "    'Does not meet the credit policy. Status:Charged Off': np.nan,\n",
    "    'Default': np.nan,\n",
    "    'Oct-2015': np.nan\n",
    "}\n",
    "'''\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "df_spark = df_spark.withColumn(\"loan_status\", when(df_spark[\"loan_status\"] == \"Fully Paid\", 0)\n",
    "                   .when(df_spark[\"loan_status\"] == \"Charged Off\", 1)\n",
    "                   .otherwise(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a37f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.fillna({col: \"nan\" if df_spark.schema[col].dataType == 'string' else np.nan for col in all_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205dda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distincts values: 3 - 1.03e-06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|loan_status|  count|\n",
      "+-----------+-------+\n",
      "|        0.0|1497783|\n",
      "|        NaN|1065163|\n",
      "|        1.0| 362547|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "value_counts = df_spark.groupBy('loan_status').count()\n",
    "value_rate = value_counts.count() / df_spark.count()\n",
    "print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83528a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('loan_amnt', 'int'),\n",
       " ('funded_amnt', 'int'),\n",
       " ('funded_amnt_inv', 'double'),\n",
       " ('term', 'string'),\n",
       " ('int_rate', 'string'),\n",
       " ('installment', 'double'),\n",
       " ('emp_title', 'string'),\n",
       " ('emp_length', 'string'),\n",
       " ('home_ownership', 'string'),\n",
       " ('annual_inc', 'string'),\n",
       " ('verification_status', 'string'),\n",
       " ('issue_d', 'string'),\n",
       " ('loan_status', 'double'),\n",
       " ('pymnt_plan', 'string'),\n",
       " ('url', 'string'),\n",
       " ('purpose', 'string'),\n",
       " ('title', 'string'),\n",
       " ('zip_code', 'string'),\n",
       " ('addr_state', 'string'),\n",
       " ('dti', 'string'),\n",
       " ('delinq_2yrs', 'double'),\n",
       " ('earliest_cr_line', 'string'),\n",
       " ('fico_range_low', 'string'),\n",
       " ('fico_range_high', 'int'),\n",
       " ('inq_last_6mths', 'int'),\n",
       " ('mths_since_last_delinq', 'int'),\n",
       " ('mths_since_last_record', 'int'),\n",
       " ('open_acc', 'int'),\n",
       " ('pub_rec', 'int'),\n",
       " ('revol_bal', 'int'),\n",
       " ('revol_util', 'string'),\n",
       " ('total_acc', 'string'),\n",
       " ('initial_list_status', 'string'),\n",
       " ('out_prncp', 'string'),\n",
       " ('out_prncp_inv', 'double'),\n",
       " ('total_pymnt', 'double'),\n",
       " ('total_pymnt_inv', 'double'),\n",
       " ('total_rec_prncp', 'double'),\n",
       " ('total_rec_int', 'double'),\n",
       " ('total_rec_late_fee', 'double'),\n",
       " ('recoveries', 'double'),\n",
       " ('collection_recovery_fee', 'double'),\n",
       " ('last_pymnt_d', 'string'),\n",
       " ('last_pymnt_amnt', 'string'),\n",
       " ('next_pymnt_d', 'string'),\n",
       " ('last_credit_pull_d', 'string'),\n",
       " ('last_fico_range_high', 'string'),\n",
       " ('last_fico_range_low', 'int'),\n",
       " ('collections_12_mths_ex_med', 'int'),\n",
       " ('mths_since_last_major_derog', 'int'),\n",
       " ('policy_code', 'int'),\n",
       " ('application_type', 'string'),\n",
       " ('annual_inc_joint', 'string'),\n",
       " ('dti_joint', 'double'),\n",
       " ('acc_now_delinq', 'int'),\n",
       " ('tot_coll_amt', 'int'),\n",
       " ('tot_cur_bal', 'int'),\n",
       " ('open_acc_6m', 'int'),\n",
       " ('open_act_il', 'int'),\n",
       " ('open_il_12m', 'int'),\n",
       " ('open_il_24m', 'int'),\n",
       " ('mths_since_rcnt_il', 'int'),\n",
       " ('total_bal_il', 'int'),\n",
       " ('il_util', 'int'),\n",
       " ('open_rv_12m', 'int'),\n",
       " ('open_rv_24m', 'int'),\n",
       " ('max_bal_bc', 'int'),\n",
       " ('all_util', 'int'),\n",
       " ('inq_fi', 'int'),\n",
       " ('total_cu_tl', 'int'),\n",
       " ('inq_last_12m', 'int'),\n",
       " ('acc_open_past_24mths', 'int'),\n",
       " ('avg_cur_bal', 'int'),\n",
       " ('bc_open_to_buy', 'int'),\n",
       " ('bc_util', 'double'),\n",
       " ('chargeoff_within_12_mths', 'double'),\n",
       " ('delinq_amnt', 'int'),\n",
       " ('mo_sin_old_il_acct', 'int'),\n",
       " ('mo_sin_old_rev_tl_op', 'int'),\n",
       " ('mo_sin_rcnt_rev_tl_op', 'int'),\n",
       " ('mo_sin_rcnt_tl', 'int'),\n",
       " ('mort_acc', 'int'),\n",
       " ('mths_since_recent_bc', 'int'),\n",
       " ('mths_since_recent_bc_dlq', 'int'),\n",
       " ('mths_since_recent_inq', 'int'),\n",
       " ('mths_since_recent_revol_delinq', 'int'),\n",
       " ('num_accts_ever_120_pd', 'int'),\n",
       " ('num_actv_bc_tl', 'int'),\n",
       " ('num_actv_rev_tl', 'int'),\n",
       " ('num_bc_sats', 'int'),\n",
       " ('num_bc_tl', 'int'),\n",
       " ('num_il_tl', 'int'),\n",
       " ('num_op_rev_tl', 'int'),\n",
       " ('num_rev_accts', 'int'),\n",
       " ('num_rev_tl_bal_gt_0', 'int'),\n",
       " ('num_sats', 'int'),\n",
       " ('num_tl_120dpd_2m', 'int'),\n",
       " ('num_tl_30dpd', 'int'),\n",
       " ('num_tl_90g_dpd_24m', 'int'),\n",
       " ('num_tl_op_past_12m', 'int'),\n",
       " ('pct_tl_nvr_dlq', 'double'),\n",
       " ('percent_bc_gt_75', 'double'),\n",
       " ('pub_rec_bankruptcies', 'int'),\n",
       " ('tax_liens', 'int'),\n",
       " ('tot_hi_cred_lim', 'int'),\n",
       " ('total_bal_ex_mort', 'int'),\n",
       " ('total_bc_limit', 'int'),\n",
       " ('total_il_high_credit_limit', 'int'),\n",
       " ('sec_app_open_act_il', 'int'),\n",
       " ('hardship_flag', 'string'),\n",
       " ('hardship_type', 'string'),\n",
       " ('hardship_reason', 'string'),\n",
       " ('hardship_status', 'string'),\n",
       " ('deferral_term', 'int'),\n",
       " ('hardship_amount', 'double'),\n",
       " ('hardship_start_date', 'string'),\n",
       " ('hardship_end_date', 'string'),\n",
       " ('payment_plan_start_date', 'string'),\n",
       " ('hardship_length', 'int'),\n",
       " ('hardship_dpd', 'int'),\n",
       " ('hardship_loan_status', 'string'),\n",
       " ('orig_projected_additional_accrued_interest', 'double'),\n",
       " ('hardship_payoff_balance_amount', 'double'),\n",
       " ('hardship_last_payment_amount', 'double'),\n",
       " ('debt_settlement_flag', 'string')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a4684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442784f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:============================>                            (7 + 7) / 14]\r",
      "\r",
      "[Stage 41:====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 145983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:================================================>       (12 + 2) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_gb = df_spark.sample(fraction=0.05, seed=1)\n",
    "print(f\"Number of data: {df_gb.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e255b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 92781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:================================================>       (12 + 2) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_gb = df_gb.dropna(subset=['loan_status'])\n",
    "print(f\"Number of data: {df_gb.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1680e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/22 09:10:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_gb = df_gb.select(all_features)\n",
    "features_collected_gb = features_gb.collect()\n",
    "target_gb = df_gb.select('loan_status')\n",
    "target_collected_gb = target_gb.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d0f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb = np.array([list(feature) for feature in features_collected_gb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee730a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gb = np.array([feature['loan_status'] for feature in target_collected_gb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2387d119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92781, 125)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48cb9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92781,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a945bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feature for (feature, dtype) in df_gb.dtypes if dtype=='string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6859dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.1319934\ttotal: 227ms\tremaining: 22.5s\n",
      "1:\tlearn: 0.0766225\ttotal: 314ms\tremaining: 15.4s\n",
      "2:\tlearn: 0.0388028\ttotal: 419ms\tremaining: 13.5s\n",
      "3:\tlearn: 0.0303303\ttotal: 492ms\tremaining: 11.8s\n",
      "4:\tlearn: 0.0235605\ttotal: 556ms\tremaining: 10.6s\n",
      "5:\tlearn: 0.0206519\ttotal: 617ms\tremaining: 9.66s\n",
      "6:\tlearn: 0.0195695\ttotal: 679ms\tremaining: 9.02s\n",
      "7:\tlearn: 0.0189217\ttotal: 741ms\tremaining: 8.52s\n",
      "8:\tlearn: 0.0175497\ttotal: 802ms\tremaining: 8.11s\n",
      "9:\tlearn: 0.0175093\ttotal: 860ms\tremaining: 7.74s\n",
      "10:\tlearn: 0.0167146\ttotal: 917ms\tremaining: 7.42s\n",
      "11:\tlearn: 0.0158007\ttotal: 990ms\tremaining: 7.26s\n",
      "12:\tlearn: 0.0157843\ttotal: 1.05s\tremaining: 7s\n",
      "13:\tlearn: 0.0123135\ttotal: 1.11s\tremaining: 6.81s\n",
      "14:\tlearn: 0.0123132\ttotal: 1.16s\tremaining: 6.55s\n",
      "15:\tlearn: 0.0120829\ttotal: 1.22s\tremaining: 6.39s\n",
      "16:\tlearn: 0.0108746\ttotal: 1.28s\tremaining: 6.23s\n",
      "17:\tlearn: 0.0108745\ttotal: 1.31s\tremaining: 5.99s\n",
      "18:\tlearn: 0.0108745\ttotal: 1.36s\tremaining: 5.8s\n",
      "19:\tlearn: 0.0108743\ttotal: 1.41s\tremaining: 5.63s\n",
      "20:\tlearn: 0.0106082\ttotal: 1.47s\tremaining: 5.54s\n",
      "21:\tlearn: 0.0105858\ttotal: 1.53s\tremaining: 5.43s\n",
      "22:\tlearn: 0.0101376\ttotal: 1.59s\tremaining: 5.33s\n",
      "23:\tlearn: 0.0099657\ttotal: 1.65s\tremaining: 5.23s\n",
      "24:\tlearn: 0.0097971\ttotal: 1.71s\tremaining: 5.13s\n",
      "25:\tlearn: 0.0097971\ttotal: 1.76s\tremaining: 5s\n",
      "26:\tlearn: 0.0090301\ttotal: 1.82s\tremaining: 4.91s\n",
      "27:\tlearn: 0.0088808\ttotal: 1.87s\tremaining: 4.82s\n",
      "28:\tlearn: 0.0088807\ttotal: 1.91s\tremaining: 4.67s\n",
      "29:\tlearn: 0.0088807\ttotal: 1.96s\tremaining: 4.57s\n",
      "30:\tlearn: 0.0088693\ttotal: 2.01s\tremaining: 4.47s\n",
      "31:\tlearn: 0.0088505\ttotal: 2.06s\tremaining: 4.38s\n",
      "32:\tlearn: 0.0088505\ttotal: 2.11s\tremaining: 4.28s\n",
      "33:\tlearn: 0.0088279\ttotal: 2.17s\tremaining: 4.21s\n",
      "34:\tlearn: 0.0088216\ttotal: 2.23s\tremaining: 4.14s\n",
      "35:\tlearn: 0.0087373\ttotal: 2.28s\tremaining: 4.06s\n",
      "36:\tlearn: 0.0078413\ttotal: 2.35s\tremaining: 3.99s\n",
      "37:\tlearn: 0.0078412\ttotal: 2.39s\tremaining: 3.91s\n",
      "38:\tlearn: 0.0066885\ttotal: 2.46s\tremaining: 3.85s\n",
      "39:\tlearn: 0.0066885\ttotal: 2.51s\tremaining: 3.76s\n",
      "40:\tlearn: 0.0065157\ttotal: 2.57s\tremaining: 3.69s\n",
      "41:\tlearn: 0.0064130\ttotal: 2.63s\tremaining: 3.63s\n",
      "42:\tlearn: 0.0063812\ttotal: 2.69s\tremaining: 3.56s\n",
      "43:\tlearn: 0.0063812\ttotal: 2.73s\tremaining: 3.48s\n",
      "44:\tlearn: 0.0063309\ttotal: 2.79s\tremaining: 3.41s\n",
      "45:\tlearn: 0.0062925\ttotal: 2.85s\tremaining: 3.35s\n",
      "46:\tlearn: 0.0061442\ttotal: 2.92s\tremaining: 3.29s\n",
      "47:\tlearn: 0.0061000\ttotal: 2.97s\tremaining: 3.22s\n",
      "48:\tlearn: 0.0060704\ttotal: 3.03s\tremaining: 3.15s\n",
      "49:\tlearn: 0.0060494\ttotal: 3.09s\tremaining: 3.09s\n",
      "50:\tlearn: 0.0060438\ttotal: 3.15s\tremaining: 3.02s\n",
      "51:\tlearn: 0.0056426\ttotal: 3.21s\tremaining: 2.96s\n",
      "52:\tlearn: 0.0055848\ttotal: 3.26s\tremaining: 2.9s\n",
      "53:\tlearn: 0.0055847\ttotal: 3.31s\tremaining: 2.82s\n",
      "54:\tlearn: 0.0055030\ttotal: 3.38s\tremaining: 2.76s\n",
      "55:\tlearn: 0.0054123\ttotal: 3.44s\tremaining: 2.7s\n",
      "56:\tlearn: 0.0050235\ttotal: 3.5s\tremaining: 2.64s\n",
      "57:\tlearn: 0.0047845\ttotal: 3.56s\tremaining: 2.58s\n",
      "58:\tlearn: 0.0047173\ttotal: 3.62s\tremaining: 2.52s\n",
      "59:\tlearn: 0.0047172\ttotal: 3.67s\tremaining: 2.45s\n",
      "60:\tlearn: 0.0046941\ttotal: 3.73s\tremaining: 2.38s\n",
      "61:\tlearn: 0.0046940\ttotal: 3.78s\tremaining: 2.32s\n",
      "62:\tlearn: 0.0046540\ttotal: 3.84s\tremaining: 2.26s\n",
      "63:\tlearn: 0.0046535\ttotal: 3.9s\tremaining: 2.19s\n",
      "64:\tlearn: 0.0046141\ttotal: 3.96s\tremaining: 2.13s\n",
      "65:\tlearn: 0.0045433\ttotal: 4.03s\tremaining: 2.07s\n",
      "66:\tlearn: 0.0044677\ttotal: 4.08s\tremaining: 2.01s\n",
      "67:\tlearn: 0.0044677\ttotal: 4.14s\tremaining: 1.95s\n",
      "68:\tlearn: 0.0043488\ttotal: 4.2s\tremaining: 1.89s\n",
      "69:\tlearn: 0.0042946\ttotal: 4.26s\tremaining: 1.83s\n",
      "70:\tlearn: 0.0042359\ttotal: 4.32s\tremaining: 1.76s\n",
      "71:\tlearn: 0.0042071\ttotal: 4.38s\tremaining: 1.7s\n",
      "72:\tlearn: 0.0041746\ttotal: 4.44s\tremaining: 1.64s\n",
      "73:\tlearn: 0.0041202\ttotal: 4.5s\tremaining: 1.58s\n",
      "74:\tlearn: 0.0041200\ttotal: 4.56s\tremaining: 1.52s\n",
      "75:\tlearn: 0.0040684\ttotal: 4.62s\tremaining: 1.46s\n",
      "76:\tlearn: 0.0040683\ttotal: 4.67s\tremaining: 1.39s\n",
      "77:\tlearn: 0.0040164\ttotal: 4.73s\tremaining: 1.33s\n",
      "78:\tlearn: 0.0039820\ttotal: 4.79s\tremaining: 1.27s\n",
      "79:\tlearn: 0.0039598\ttotal: 4.85s\tremaining: 1.21s\n",
      "80:\tlearn: 0.0039597\ttotal: 4.89s\tremaining: 1.15s\n",
      "81:\tlearn: 0.0039349\ttotal: 4.96s\tremaining: 1.09s\n",
      "82:\tlearn: 0.0039181\ttotal: 5.04s\tremaining: 1.03s\n",
      "83:\tlearn: 0.0038998\ttotal: 5.11s\tremaining: 973ms\n",
      "84:\tlearn: 0.0038938\ttotal: 5.16s\tremaining: 911ms\n",
      "85:\tlearn: 0.0038823\ttotal: 5.22s\tremaining: 850ms\n",
      "86:\tlearn: 0.0038823\ttotal: 5.27s\tremaining: 788ms\n",
      "87:\tlearn: 0.0038822\ttotal: 5.32s\tremaining: 725ms\n",
      "88:\tlearn: 0.0038421\ttotal: 5.38s\tremaining: 665ms\n",
      "89:\tlearn: 0.0037379\ttotal: 5.45s\tremaining: 606ms\n",
      "90:\tlearn: 0.0037174\ttotal: 5.51s\tremaining: 545ms\n",
      "91:\tlearn: 0.0037173\ttotal: 5.56s\tremaining: 483ms\n",
      "92:\tlearn: 0.0036843\ttotal: 5.62s\tremaining: 423ms\n",
      "93:\tlearn: 0.0036596\ttotal: 5.68s\tremaining: 363ms\n",
      "94:\tlearn: 0.0036312\ttotal: 5.74s\tremaining: 302ms\n",
      "95:\tlearn: 0.0036311\ttotal: 5.79s\tremaining: 241ms\n",
      "96:\tlearn: 0.0036191\ttotal: 5.84s\tremaining: 181ms\n",
      "97:\tlearn: 0.0036191\ttotal: 5.89s\tremaining: 120ms\n",
      "98:\tlearn: 0.0036137\ttotal: 5.95s\tremaining: 60.1ms\n",
      "99:\tlearn: 0.0035804\ttotal: 6.01s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7d90b89c60e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "pool = Pool(data=X_gb, label=y_gb, feature_names=all_features, cat_features=categorical_features)\n",
    "\n",
    "catboost_model = CatBoostClassifier(iterations=100)\n",
    "catboost_model.fit(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbc2cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(catboost_model)\n",
    "shap_values = explainer.shap_values(X_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8587e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>417046.553348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>149158.378179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <td>135989.706385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>128005.130072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>93815.640670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <td>1.477193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico_range_low</th>\n",
       "      <td>0.305097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>0.073228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_flag</th>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature_importance\n",
       "total_rec_prncp            417046.553348\n",
       "recoveries                 149158.378179\n",
       "last_fico_range_low        135989.706385\n",
       "loan_amnt                  128005.130072\n",
       "funded_amnt_inv             93815.640670\n",
       "...                                  ...\n",
       "hardship_loan_status            1.477193\n",
       "fico_range_low                  0.305097\n",
       "open_acc_6m                     0.073228\n",
       "verification_status             0.000302\n",
       "hardship_flag                   0.000125\n",
       "\n",
       "[106 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_over_feature = np.sum(np.abs(shap_values), axis=0)\n",
    "feature_importance = pd.DataFrame(data=sum_over_feature, index=all_features, columns=['feature_importance'])\n",
    "feature_importance = feature_importance[feature_importance['feature_importance']>0]\n",
    "feature_importance = feature_importance.sort_values(by='feature_importance', ascending=False)\n",
    "feature_importance.shape\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39cbd894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>417046.553348</td>\n",
       "      <td>4.170466e+05</td>\n",
       "      <td>0.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>149158.378179</td>\n",
       "      <td>5.662049e+05</td>\n",
       "      <td>0.411007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <td>135989.706385</td>\n",
       "      <td>7.021946e+05</td>\n",
       "      <td>0.509721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>128005.130072</td>\n",
       "      <td>8.301998e+05</td>\n",
       "      <td>0.602640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>93815.640670</td>\n",
       "      <td>9.240154e+05</td>\n",
       "      <td>0.670740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <td>1.477193</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico_range_low</th>\n",
       "      <td>0.305097</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>0.073228</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_flag</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature_importance  cumulative_sum      rate\n",
       "total_rec_prncp            417046.553348    4.170466e+05  0.302733\n",
       "recoveries                 149158.378179    5.662049e+05  0.411007\n",
       "last_fico_range_low        135989.706385    7.021946e+05  0.509721\n",
       "loan_amnt                  128005.130072    8.301998e+05  0.602640\n",
       "funded_amnt_inv             93815.640670    9.240154e+05  0.670740\n",
       "...                                  ...             ...       ...\n",
       "hardship_loan_status            1.477193    1.377605e+06  1.000000\n",
       "fico_range_low                  0.305097    1.377605e+06  1.000000\n",
       "open_acc_6m                     0.073228    1.377605e+06  1.000000\n",
       "verification_status             0.000302    1.377605e+06  1.000000\n",
       "hardship_flag                   0.000125    1.377605e+06  1.000000\n",
       "\n",
       "[106 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance['cumulative_sum'] = feature_importance['feature_importance'].cumsum()\n",
    "total_sum = feature_importance['feature_importance'].sum()\n",
    "feature_importance['rate'] = feature_importance['cumulative_sum'] / total_sum\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bdd2694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "selected_features = feature_importance[feature_importance['rate'] < threshold].index\n",
    "selected_features\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d8b87fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = [feature for feature in all_features if feature not in selected_features]\n",
    "features_to_drop\n",
    "len(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de6d755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(*features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8720722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView(\"lending_club\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dbace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "to_float_udf = udf(to_float, FloatType())\n",
    "df_spark = df_spark.withColumn(\"last_fico_range_high\", to_float_udf(df_spark[\"last_fico_range_high\"]))\n",
    "df_spark = df_spark.withColumn(\"last_pymnt_amnt\", to_float_udf(df_spark[\"last_pymnt_amnt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8de72519",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_expression = \"\"\"\n",
    "CASE\n",
    "    WHEN last_pymnt_d LIKE 'Jan-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 0/12\n",
    "    WHEN last_pymnt_d LIKE 'Feb-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 1/12\n",
    "    WHEN last_pymnt_d LIKE 'Mar-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 2/12\n",
    "    WHEN last_pymnt_d LIKE 'Apr-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 3/12\n",
    "    WHEN last_pymnt_d LIKE 'May-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 4/12\n",
    "    WHEN last_pymnt_d LIKE 'Jun-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 5/12\n",
    "    WHEN last_pymnt_d LIKE 'Jul-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 6/12\n",
    "    WHEN last_pymnt_d LIKE 'Aug-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 7/12\n",
    "    WHEN last_pymnt_d LIKE 'Sep-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 8/12\n",
    "    WHEN last_pymnt_d LIKE 'Oct-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 9/12\n",
    "    WHEN last_pymnt_d LIKE 'Nov-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 10/12\n",
    "    WHEN last_pymnt_d LIKE 'Dec-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 11/12\n",
    "    ELSE NULL\n",
    "END AS last_pymnt_d_num\n",
    "\"\"\"\n",
    "df_spark = spark.sql(f\"\"\"\n",
    "SELECT *, {sql_expression}\n",
    "FROM lending_club\n",
    "\"\"\")\n",
    "\n",
    "df_spark = df_spark.drop(\"last_pymnt_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_pymnt_d_num', 'last_pymnt_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a41c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_expression = \"\"\"\n",
    "CASE\n",
    "    WHEN last_credit_pull_d LIKE 'Jan-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 0/12\n",
    "    WHEN last_credit_pull_d LIKE 'Feb-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 1/12\n",
    "    WHEN last_credit_pull_d LIKE 'Mar-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 2/12\n",
    "    WHEN last_credit_pull_d LIKE 'Apr-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 3/12\n",
    "    WHEN last_credit_pull_d LIKE 'May-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 4/12\n",
    "    WHEN last_credit_pull_d LIKE 'Jun-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 5/12\n",
    "    WHEN last_credit_pull_d LIKE 'Jul-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 6/12\n",
    "    WHEN last_credit_pull_d LIKE 'Aug-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 7/12\n",
    "    WHEN last_credit_pull_d LIKE 'Sep-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 8/12\n",
    "    WHEN last_credit_pull_d LIKE 'Oct-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 9/12\n",
    "    WHEN last_credit_pull_d LIKE 'Nov-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 10/12\n",
    "    WHEN last_credit_pull_d LIKE 'Dec-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 11/12\n",
    "    ELSE NULL\n",
    "END AS last_credit_pull_d_num\n",
    "\"\"\"\n",
    "df_spark = spark.sql(f\"\"\"\n",
    "SELECT *, {sql_expression}\n",
    "FROM lending_club\n",
    "\"\"\")\n",
    "\n",
    "df_spark = df_spark.drop(\"last_credit_pull_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_credit_pull_d_num', 'last_credit_pull_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ddc7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(\"last_pymnt_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_pymnt_d_num', 'last_pymnt_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a3645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_float_rate = udf(lambda x: float(x.replace('%', '')) / 100, FloatType())\n",
    "df_spark = df_spark.withColumn('int_rate', convert_to_float_rate(df_spark['int_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab30efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "numerical_selected_features = [feature for (feature, dtype) in df_spark.dtypes if (dtype!='string' and feature !='loan_status')]\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_selected_features,\n",
    "    outputCols=numerical_selected_features\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "df_spark = imputer.fit(df_spark).transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a751f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import isnan\n",
    "# for feature, dtype in df_spark.dtypes:\n",
    "#     print(\"====================================\")\n",
    "#     print(f\"FEATURE: {feature}\")\n",
    "#     if dtype=='string':\n",
    "#         value_counts = df_spark.groupBy(feature).count()\n",
    "#         value_rate = value_counts.count() / df_spark.count()\n",
    "#         print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "#         value_counts.show()\n",
    "#     nan_count = df_spark.filter(df_spark[feature].isNull() | isnan(df_spark[feature])).count()\n",
    "#     nan_rate = nan_count / df_spark.count()\n",
    "#     print(f\"{nan_count} NaN - {nan_rate:.2e} %\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f79120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 14518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled data: 9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 58:========================================>               (10 + 4) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df_spark.sample(fraction=0.005, seed=1)\n",
    "print(f\"Number of data: {df.count()}\")\n",
    "df_labeled = df.dropna(subset=['loan_status'])\n",
    "print(f\"Number of labeled data: {df_labeled.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b745349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN data: 5271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan\n",
    "df_nan = df.filter(isnan(df['loan_status']))\n",
    "print(f\"Number of NaN data: {df_nan.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "756ac9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [feature for feature in list(df_spark.columns) if feature != 'loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f8eb7743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_collected = df_labeled.select(features).collect()\n",
    "target_collected = df_labeled.select('loan_status').collect()\n",
    "X_labeled = np.array([list(feature) for feature in features_collected], dtype=float)\n",
    "y_labeled = np.array([feature['loan_status'] for feature in target_collected], dtype=float)\n",
    "y_labeled = y_labeled.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "27ac3077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loan_status\n",
       "loan_status          1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "\n",
    "features_pcorr = pd.DataFrame(X_labeled.astype(float), columns=features)\n",
    "df_combined['loan_status'] = y_labeled\n",
    "pcorr_matrix = df_combined.pcorr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pcorr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, cbar_kws={'label': 'Partial Correlation'})\n",
    "plt.title('Partial Correlation Heatmap')\n",
    "plt.show()\n",
    "pcorr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6636f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_collected = df_nan.select(features).collect()\n",
    "X_unlabeled = np.array([list(feature) for feature in features_collected], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b383f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = np.unique(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3b5568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from captum.attr import IntegratedGradients\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from mapie.classification import MapieClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from skopt import BayesSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layer_sizes, activation_name, p_dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        if isinstance(self.hidden_layer_sizes, str):\n",
    "            self.hidden_layer_sizes = eval(self.hidden_layer_sizes)\n",
    "        self.activation_name = activation_name\n",
    "        self.p_dropout = p_dropout\n",
    "        if activation_name == \"Relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_name == \"Sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation_name == \"Softmax\":\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        elif activation_name == \"Tanh\":\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation_name == \"Leaky_relu\":\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported activation: {self.activation_name}')\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.input_size, self.hidden_layer_sizes[0]))\n",
    "        layers.append(self.activation)\n",
    "        for i in range(len(self.hidden_layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(self.hidden_layer_sizes[i], self.hidden_layer_sizes[i + 1]))\n",
    "            layers.append(self.activation)\n",
    "            layers.append(nn.Dropout(p=self.p_dropout))\n",
    "        layers.append(nn.Linear(self.hidden_layer_sizes[-1], self.output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward_proba(self, X):\n",
    "        output = self.model(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output.float()\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.model(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MLPEstimatorSklearn():\n",
    "    def __init__(self, **params):\n",
    "        self.input_size = params.get(\"input_size\")\n",
    "        self.output_size = params.get(\"output_size\")\n",
    "        self.hidden_layer_sizes = params.get(\"hidden_layer_sizes\", (60, 60))\n",
    "        self.activation_name = params.get(\"activation_name\", \"Relu\")\n",
    "        self.loss = params.get(\"loss\", \"binary_cross_entropy\")\n",
    "        self.optimizer_name = params.get(\"optimizer_name\", \"Adam\")\n",
    "        self.learning_rate = params.get(\"learning_rate\", 1e-3)\n",
    "        self.batch_size = params.get(\"batch_size\", 50)\n",
    "        self.weight_decay = params.get(\"weight_decay\", 0)\n",
    "        self.p_dropout = params.get(\"p_dropout\", 0.2)\n",
    "        self.early_stopping = params.get(\"early_stopping\", True)\n",
    "        self.epochs = params.get(\"epochs\", 200)\n",
    "        self.patience = params.get(\"patience\", 10)\n",
    "        self.verbose = params.get(\"verbose\", True)\n",
    "        self.classes_ = classes_\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = MLP(self.input_size, self.output_size, self.hidden_layer_sizes, self.activation_name, self.p_dropout).to(self.device)\n",
    "\n",
    "        if self.loss == \"binary_cross_entropy\":\n",
    "            self.criterion = nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported loss: {self.loss}\")\n",
    "\n",
    "        if self.optimizer_name == \"SGD\":\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=self.weight_decay)\n",
    "        elif self.optimizer_name == \"Adam\":\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {self.optimizer}\")\n",
    "            \n",
    "    def next_batch(self, inputs, targets, batchSize):\n",
    "        inputs_tensor = torch.from_numpy(inputs).float()\n",
    "        targets_tensor = torch.from_numpy(targets).float().unsqueeze(1)\n",
    "        for i in range(0, inputs_tensor.shape[0], batchSize):\n",
    "            yield (inputs_tensor[i:i + batchSize], targets_tensor[i:i + batchSize])\n",
    "\n",
    "    def augment_data(self, X_unlabeled, noise_level=0.1):\n",
    "        noise = noise_level * torch.randn_like(X_unlabeled)\n",
    "        return X_unlabeled + noise\n",
    "            \n",
    "    def fit(self, X, y, X_unlabeled=None):\n",
    "        self.classes_ = np.unique(y)\n",
    "        running_losses_1 = list()\n",
    "        if self.early_stopping:\n",
    "            best_loss = float('inf')\n",
    "            count = 0\n",
    "        if self.verbose:\n",
    "            epoch_iterator_1 = tqdm(range(self.epochs), desc=\"Supervised training ; epochs\", unit=\"epoch\")\n",
    "        else:\n",
    "            epoch_iterator_1 = range(self.epochs)\n",
    "        for epoch in epoch_iterator_1:\n",
    "            samples = 0\n",
    "            train_loss = 0.0\n",
    "            self.model.train(True)\n",
    "            for i, (batchX, batchY) in enumerate(self.next_batch(X, y, self.batch_size)):\n",
    "                batchX = batchX.to(self.device)\n",
    "                batchY = batchY.to(self.device)\n",
    "                batchY.requires_grad = True\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(batchX)\n",
    "                loss = self.criterion(outputs, batchY)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                samples += batchY.size(0)\n",
    "            running_loss = train_loss / samples\n",
    "            running_losses_1.append(running_loss)\n",
    "            if self.verbose:\n",
    "                epoch_iterator_1.set_postfix(train_loss=running_loss)\n",
    "            if self.early_stopping:\n",
    "                if running_loss < best_loss:\n",
    "                    best_loss = running_loss\n",
    "                    count = 0\n",
    "                else:\n",
    "                    count += 1\n",
    "                if count >= self.patience:\n",
    "                    break\n",
    "        if self.verbose:\n",
    "            epoch_iterator_1.close()\n",
    "        self.running_losses_1 = [loss for loss in running_losses_1 if loss <= best_loss]\n",
    "        if X_unlabeled is not None:\n",
    "            best_loss = float('inf')\n",
    "            running_losses_2 = list()\n",
    "            X_unlabeled = torch.from_numpy(X_unlabeled).float()\n",
    "            augmented_X_unlabeled = self.augment_data(X_unlabeled)\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                pseudo_labels = self.model(X_unlabeled)\n",
    "                pseudo_labels = (pseudo_labels > 0.5).float().squeeze()\n",
    "            \n",
    "            X_combined = torch.cat((torch.from_numpy(X).float(), augmented_X_unlabeled.cpu()), 0).to(self.device)\n",
    "            y_combined = torch.cat((torch.from_numpy(y).float().squeeze(), pseudo_labels), 0).to(self.device)\n",
    "\n",
    "            if self.verbose:\n",
    "                epoch_iterator_2 = tqdm(range(self.epochs), desc=\"Semi-supervised training ; epochs\", unit=\"epoch\")\n",
    "            else:\n",
    "                epoch_iterator_2 = range(self.epochs)\n",
    "            for epoch in epoch_iterator_2:\n",
    "                samples = 0\n",
    "                train_loss = 0.0\n",
    "                self.model.train(True)\n",
    "                dataset = TensorDataset(X_combined, y_combined)\n",
    "                for i, (batchX, batchY) in enumerate(self.next_batch(X, y, self.batch_size)):\n",
    "                    batchX = batchX.to(self.device)\n",
    "                    batchY = batchY.to(self.device)\n",
    "                    batchY.requires_grad = True\n",
    "                    self.optimizer.zero_grad()\n",
    "                    outputs = self.model(batchX)\n",
    "                    loss = self.criterion(outputs, batchY)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                    samples += batchY.size(0)\n",
    "                running_loss = train_loss / samples\n",
    "                running_losses_2.append(running_loss)\n",
    "                if self.verbose:\n",
    "                    epoch_iterator_2.set_postfix(train_loss=running_loss)\n",
    "                if self.early_stopping:\n",
    "                    if running_loss < best_loss:\n",
    "                        best_loss = running_loss\n",
    "                        count = 0\n",
    "                    else:\n",
    "                        count += 1\n",
    "                    if count >= self.patience:\n",
    "                        break\n",
    "            if self.verbose:\n",
    "                epoch_iterator_2.close()\n",
    "            self.running_losses_2 = [loss for loss in running_losses_2 if loss <= best_loss]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X = torch.from_numpy(X).float().to(self.device)\n",
    "        y_pred = self.model.forward(X)\n",
    "        if self.device == \"cpu\":\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "        else:\n",
    "            y_pred = y_pred.detach().numpy()\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        X = torch.from_numpy(X).float().to(self.device)\n",
    "        y_proba = self.model.forward_proba(X)\n",
    "        if self.device == \"cpu\":\n",
    "            y_proba = y_proba.cpu().detach().numpy().astype(float)\n",
    "        else:\n",
    "            y_proba = y_proba.detach().numpy().astype(float)\n",
    "        y_proba = y_proba.squeeze().astype(np.float32)\n",
    "        return np.column_stack((1 - y_proba, y_proba))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = {\n",
    "            \"input_size\": self.input_size,\n",
    "            \"output_size\": self.output_size,\n",
    "            \"hidden_layer_sizes\": self.hidden_layer_sizes,\n",
    "            \"activation_name\": self.activation_name,\n",
    "            \"loss\": self.loss,\n",
    "            \"optimizer_name\": self.optimizer_name,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"p_dropout\": self.p_dropout,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"patience\": self.patience,\n",
    "            \"verbose\": self.verbose\n",
    "        }\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "    def get_mlp(self):\n",
    "        return self.model\n",
    "    \n",
    "class MLPBinaryClassifier():\n",
    "    def __init__(self, X, y, split_test, X_unlabeled=None, **params):\n",
    "        self.model = MLPEstimatorSklearn(**params)\n",
    "        self.X = X\n",
    "        self.X_unlabeled = X_unlabeled\n",
    "        self.y = y\n",
    "        \n",
    "        self.y = MLPBinaryClassifier.float_to_class(self.y).ravel()\n",
    "        \n",
    "        self.split_test = split_test\n",
    "        self.split_data()\n",
    "        \n",
    "        self.standardize(self.X_train_cal)\n",
    "        self.X_train_standard = self.standardize_X(self.X_train)\n",
    "        self.X_cal_standard = self.standardize_X(self.X_cal)\n",
    "        if isinstance(self.X_unlabeled, np.ndarray):\n",
    "            self.X_unlabeled_standard = self.standardize_X(self.X_unlabeled)\n",
    "        else :\n",
    "            self.X_unlabeled_standard = None\n",
    "        self.y_train_standard = self.y_train\n",
    "        self.y_cal_standard = self.y_cal.reshape(-1,1)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def float_to_class(y):\n",
    "        threshold = 0.5\n",
    "        return (y >= threshold).astype(int)\n",
    "    \n",
    "    def split_data(self):\n",
    "        self.X_train_cal, self.X_test, self.y_train_cal, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=self.split_test, shuffle=True, random_state=1, stratify=self.y)\n",
    "        self.X_train, self.X_cal, self.y_train, self.y_cal = train_test_split(\n",
    "            self.X_train_cal, self.y_train_cal, test_size=0.25, shuffle=True, random_state=1, stratify=self.y_train_cal)\n",
    "\n",
    "    def standardize(self, X):\n",
    "        self.scaler_X_train = StandardScaler()\n",
    "        self.scaler_X_train.fit(X)         \n",
    "\n",
    "\n",
    "    def standardize_X(self, X):\n",
    "        X_new = self.scaler_X_train.transform(X)\n",
    "        return X_new\n",
    "    \n",
    "\n",
    "\n",
    "    def bayes_search(self, param_bayes, n_iter, n_points=1, cv=5, scoring='accuracy',\n",
    "                 verbose=3, n_jobs=1) :\n",
    "        cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "        bayes_search = BayesSearchCV(self.model, param_bayes, n_iter=n_iter,\n",
    "                                     n_points=n_points, cv=cv, scoring=scoring,\n",
    "                                     verbose=verbose, return_train_score=True,\n",
    "                                     n_jobs=n_jobs, random_state=1)\n",
    "        bayes_search.fit(self.X_train_standard, self.y_train_standard)\n",
    "        results_df = pd.DataFrame(bayes_search.cv_results_)\n",
    "        self.model = bayes_search.best_estimator_\n",
    "        print(f'Best hyperparameters bayes search : {bayes_search.best_params_}')\n",
    "        return results_df\n",
    "\n",
    "    def randomized_search(self, param_randomized, n_iter, cv=5, scoring='accuracy',\n",
    "                      verbose=3, n_jobs=1) :\n",
    "        cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "        randomized_search = RandomizedSearchCV(self.model, param_randomized,\n",
    "                                               n_iter=n_iter, cv=cv, scoring=scoring,\n",
    "                                               verbose=verbose, return_train_score=True,\n",
    "                                               n_jobs=n_jobs, random_state=1)\n",
    "        randomized_search.fit(self.X_train_standard, self.y_train_standard)\n",
    "        results_df = pd.DataFrame(randomized_search.cv_results_)\n",
    "        self.model = randomized_search.best_estimator_\n",
    "        print(f'Best hyperparameters randomized search : {randomized_search.best_params_}')\n",
    "        return results_df\n",
    "\n",
    "    def fit(self, method=\"lac\"):\n",
    "        self.model.fit(self.X_train_standard, self.y_train_standard, self.X_unlabeled_standard)\n",
    "        self.model_mapie = MapieClassifier(estimator=self.model, cv=\"prefit\", method=method)\n",
    "        self.model_mapie.fit(self.X_cal_standard, self.y_cal_standard)\n",
    "\n",
    "    def predict(self, X, alpha=0.05):\n",
    "        X_standard = self.standardize_X(X)\n",
    "        y_pred, y_ps = self.model_mapie.predict(X_standard, alpha=alpha)\n",
    "        return y_pred, y_ps\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_metrics(metric, y_true, y_pred):\n",
    "        y_pred = MLPBinaryClassifier.float_to_class(y_pred)\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "        precision = metrics.precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall = metrics.recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "        metrics_dict = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "        }\n",
    "        if metric != 'all':\n",
    "            metrics_dict = {metric: metrics_dict[metric]}\n",
    "        return metrics_dict\n",
    "\n",
    "\n",
    "    def model_performance(self, metric='all'):\n",
    "        y_pred_train, _ = self.predict(self.X_train)\n",
    "        scores_train = MLPBinaryClassifier.compute_metrics(metric, self.y_train, y_pred_train)\n",
    "        y_pred_test, _ = self.predict(self.X_test)\n",
    "        scores_test = MLPBinaryClassifier.compute_metrics(metric, self.y_test, y_pred_test)\n",
    "        data = {}\n",
    "        for key, value in scores_train.items():\n",
    "            data['Train Set - '+key] = [value]\n",
    "        for key, value in scores_test.items():\n",
    "            data['Test Set - '+key] = [value]\n",
    "        df_scores = pd.DataFrame(data=data).T\n",
    "        df_scores.columns = ['Scores']\n",
    "        return df_scores\n",
    "\n",
    "    def model_performance_test(self, X_test, y_test, metric='all'):\n",
    "        y_pred_test, _ = self.predict(X_test)\n",
    "        scores_test = MLPBinaryClassifier.compute_metrics(metric, y_test, y_pred_test)\n",
    "        data = {}\n",
    "        for key, value in scores_test.items():\n",
    "            data['Test Set - '+key] = [value]\n",
    "        df_scores = pd.DataFrame(data=data).T\n",
    "        df_scores.columns = ['Scores']\n",
    "        return df_scores\n",
    "\n",
    "    def receiver_operating_characteristics(self):\n",
    "        y_pred_test, _ = self.predict(self.X_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(self.y_test, y_pred_test)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(\"Receiver Operating Characteristics\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.show()\n",
    "\n",
    "    def compute_integrated_gradients(self, X, baseline=None, steps=50):\n",
    "        def preprocess_input(X):\n",
    "            return torch.tensor(X, dtype=torch.float32)\n",
    "        input_tensor = preprocess_input(X)\n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(input_tensor)\n",
    "        integrated_gradients = IntegratedGradients(self.model.get_mlp())\n",
    "        attributions = integrated_gradients.attribute(input_tensor, baseline, target=0, n_steps=steps)\n",
    "        attributions_df = pd.DataFrame(attributions.cpu().detach().numpy(), columns=features)\n",
    "        avg_attributions = attributions_df.mean(axis=0)\n",
    "        avg_abs_attributions = avg_attributions.abs()\n",
    "        def custom_minmax_scaler(data, feature_range=(0, 100)):\n",
    "            min_val = np.min(data)\n",
    "            max_val = np.max(data)\n",
    "            if max_val - min_val == 0:\n",
    "                return np.zeros_like(data) if feature_range[0] == 0 else np.full_like(data, feature_range[0])\n",
    "            scale = (feature_range[1] - feature_range[0]) / (max_val - min_val)\n",
    "            min_range = feature_range[0]\n",
    "            scaled_data = scale * (data - min_val) + min_range\n",
    "            return scaled_data\n",
    "        normalized_data = custom_minmax_scaler(avg_abs_attributions.values.reshape(-1, 1)).astype(float)\n",
    "        np.set_printoptions(suppress=True, precision=2)\n",
    "        normalized_attributions = pd.DataFrame(normalized_data, columns=['attribution'], index=features)\n",
    "        sorted_attributions = normalized_attributions.sort_values(by=\"attribution\", ascending=False)\n",
    "        return sorted_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab236126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "from skopt.space import Real\n",
    "\n",
    "params = {    \n",
    "    \"init\" : {\n",
    "        \"input_size\" : len(features),\n",
    "        \"output_size\" : 1,\n",
    "        \"hidden_layer_sizes\" : (60,60),\n",
    "        \"activation_name\" : \"Relu\",\n",
    "        \"optimizer_name\" : \"Adam\",\n",
    "        \"learning_rate\" : 1e-3,\n",
    "        \"batch_size\" : 50,\n",
    "        \"weight_decay\" : 0,\n",
    "        \"p_dropout\" : 0.3,\n",
    "        \"loss\" : \"binary_cross_entropy\",\n",
    "        \"early_stopping\" : True,\n",
    "        \"epochs\" : 200,\n",
    "        \"patience\" : 10,\n",
    "        \"verbose\" : True\n",
    "    },\n",
    "    \"randomized\": {\n",
    "        \"hidden_layer_sizes\" : [(10,),(50,),(100,),(10,10),(50,50),(60,60),(100,50),(100,100),(100,50,25)],\n",
    "        \"activation_name\" :  [\"Relu\", \"Sigmoid\", \"Tanh\", \"Leaky_relu\", \"Softmax\"],\n",
    "        \"learning_rate\" : loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\" : list(np.arange(10,500, 10)),\n",
    "        \"optimizer_name\" : [\"Adam\", \"SGD\"],\n",
    "        \"alpha\" : np.logspace(-3,0,19),\n",
    "        \"weight_decay\" : loguniform(1e-5, 1),\n",
    "        \"p_dropout\" : uniform(0, 0.4)   \n",
    "    },\n",
    "    \"bayes\": {\n",
    "        \"hidden_layer_sizes\" : [\"(10,)\",\"(50,)\",\"(100,)\",\"(10,10)\",\"(50,50)\",\"(60,60)\",\"(100,50)\",\"(100,100)\",\"(100,50,25)\"],\n",
    "        \"activation_name\" :  [\"Relu\", \"Sigmoid\", \"Tanh\", \"Leaky_relu\", \"Softmax\"],\n",
    "        \"learning_rate\" : Real(1e-4, 1e-1, prior='log-uniform'),\n",
    "        \"batch_size\" : list(np.arange(10,500, 10)),\n",
    "        \"optimizer_name\" : [\"Adam\", \"SGD\"],\n",
    "        \"alpha\" : np.logspace(-3,0,19),\n",
    "        \"weight_decay\" : Real(1e-5, 1, prior='log-uniform'),\n",
    "        \"p_dropout\" : Real(0, 0.4, prior='uniform')\n",
    "    }\n",
    "}\n",
    "\n",
    "model_mlp = MLPBinaryClassifier(X=X_labeled, y=y_labeled, X_unlabeled=X_unlabeled, split_test=0.2, **params[\"init\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02818466",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5\n",
    "n_points=1\n",
    "cv=5\n",
    "scoring='accuracy'\n",
    "verbose=3\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5845bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mlp.bayes_search(\n",
    "#     param_bayes=params['bayes'],\n",
    "#     n_iter=n_iter,\n",
    "#     n_points=n_points,\n",
    "#     cv=cv,\n",
    "#     scoring=scoring,\n",
    "#     n_jobs=n_jobs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d63527ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  57%|█████▋    | 114/200 [00:05<00:03, 21.93epoch/s, train_loss=5.43e-6]\n",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s]53epoch/s, train_loss=5.18e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation_name=Softmax, alpha=0.01, batch_size=260, hidden_layer_sizes=(100,), learning_rate=0.034588581370567514, optimizer_name=SGD, p_dropout=0.2740878001587038, weight_decay=0.00010525948689799706;, score=(train=1.000, test=0.996) total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  37%|███▋      | 74/200 [00:07<00:13,  9.40epoch/s, train_loss=1.6e-5] ]\n",
      "Supervised training ; epochs:  90%|█████████ | 180/200 [00:08<00:00, 22.66epoch/s, train_loss=1.53e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation_name=Leaky_relu, alpha=0.1, batch_size=90, hidden_layer_sizes=(60, 60), learning_rate=0.0002755926764027377, optimizer_name=Adam, p_dropout=0.15863229091841047, weight_decay=0.0008700690210600529;, score=(train=1.000, test=0.997) total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs: 100%|██████████| 200/200 [00:09<00:00, 21.73epoch/s, train_loss=9.6e-7] \n",
      "Supervised training ; epochs:  97%|█████████▋| 194/200 [00:09<00:00, 21.34epoch/s, train_loss=1.05e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation_name=Softmax, alpha=0.01, batch_size=260, hidden_layer_sizes=(100,), learning_rate=0.034588581370567514, optimizer_name=SGD, p_dropout=0.2740878001587038, weight_decay=0.00010525948689799706;, score=(train=1.000, test=0.997) total time=   9.2s\n",
      "[CV 3/5] END activation_name=Softmax, alpha=0.01, batch_size=260, hidden_layer_sizes=(100,), learning_rate=0.034588581370567514, optimizer_name=SGD, p_dropout=0.2740878001587038, weight_decay=0.00010525948689799706;, score=(train=1.000, test=0.996) total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  42%|████▏     | 83/200 [00:10<00:14,  8.20epoch/s, train_loss=1.05e-5]\n",
      "Supervised training ; epochs:  42%|████▎     | 85/200 [00:10<00:13,  8.33epoch/s, train_loss=7.01e-6]\n",
      "Supervised training ; epochs:  50%|█████     | 100/200 [00:04<00:04, 22.52epoch/s, train_loss=6.6e-6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation_name=Leaky_relu, alpha=0.1, batch_size=90, hidden_layer_sizes=(60, 60), learning_rate=0.0002755926764027377, optimizer_name=Adam, p_dropout=0.15863229091841047, weight_decay=0.0008700690210600529;, score=(train=1.000, test=0.995) total time=  10.1s\n",
      "[CV 3/5] END activation_name=Leaky_relu, alpha=0.1, batch_size=90, hidden_layer_sizes=(60, 60), learning_rate=0.0002755926764027377, optimizer_name=Adam, p_dropout=0.15863229091841047, weight_decay=0.0008700690210600529;, score=(train=1.000, test=0.996) total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  48%|████▊     | 97/200 [00:11<00:12,  8.49epoch/s, train_loss=3.43e-5]]\n",
      "Supervised training ; epochs:  65%|██████▌   | 130/200 [00:06<00:03, 20.64epoch/s, train_loss=3.49e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation_name=Leaky_relu, alpha=0.1, batch_size=90, hidden_layer_sizes=(60, 60), learning_rate=0.0002755926764027377, optimizer_name=Adam, p_dropout=0.15863229091841047, weight_decay=0.0008700690210600529;, score=(train=0.998, test=0.998) total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  52%|█████▏    | 104/200 [00:12<00:11,  8.60epoch/s, train_loss=5e-6]   \n",
      "Supervised training ; epochs:  74%|███████▍  | 148/200 [00:07<00:02, 20.51epoch/s, train_loss=2.39e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation_name=Leaky_relu, alpha=0.1, batch_size=90, hidden_layer_sizes=(60, 60), learning_rate=0.0002755926764027377, optimizer_name=Adam, p_dropout=0.15863229091841047, weight_decay=0.0008700690210600529;, score=(train=1.000, test=0.995) total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  78%|███████▊  | 156/200 [00:07<00:02, 20.72epoch/s, train_loss=2.15e-6]\n",
      "Supervised training ; epochs:  50%|█████     | 100/200 [00:04<00:04, 20.24epoch/s, train_loss=5.04e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation_name=Softmax, alpha=0.01, batch_size=260, hidden_layer_sizes=(100,), learning_rate=0.034588581370567514, optimizer_name=SGD, p_dropout=0.2740878001587038, weight_decay=0.00010525948689799706;, score=(train=1.000, test=0.997) total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  10%|█         | 20/200 [00:04<00:32,  5.49epoch/s, train_loss=0.000127]\n",
      "Supervised training ; epochs:   6%|▌         | 12/200 [00:01<00:26,  7.12epoch/s, train_loss=0.000178]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation_name=Softmax, alpha=0.01, batch_size=260, hidden_layer_sizes=(100,), learning_rate=0.034588581370567514, optimizer_name=SGD, p_dropout=0.2740878001587038, weight_decay=0.00010525948689799706;, score=(train=1.000, test=0.999) total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  37%|███▋      | 74/200 [00:09<00:15,  8.00epoch/s, train_loss=1.76e-5] \n",
      "Supervised training ; epochs:  28%|██▊       | 55/200 [00:10<00:28,  5.17epoch/s, train_loss=1e-5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=0.999, test=0.995) total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  30%|███       | 61/200 [00:12<00:28,  4.91epoch/s, train_loss=2.01e-5] \n",
      "Supervised training ; epochs:  32%|███▎      | 65/200 [00:08<00:16,  8.15epoch/s, train_loss=1.64e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=0.998, test=0.996) total time=  12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  42%|████▏     | 84/200 [00:10<00:14,  7.89epoch/s, train_loss=2.74e-5]]\n",
      "Supervised training ; epochs:   2%|▏         | 3/200 [00:00<00:06, 29.58epoch/s, train_loss=0.000529]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=1.000, test=0.995) total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  36%|███▌      | 71/200 [00:13<00:25,  5.16epoch/s, train_loss=1.04e-5] \n",
      "Supervised training ; epochs:  10%|▉         | 19/200 [00:00<00:05, 33.90epoch/s, train_loss=7.63e-5]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=1.000, test=0.995) total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  42%|████▏     | 84/200 [00:11<00:15,  7.60epoch/s, train_loss=3.45e-6] \n",
      "Supervised training ; epochs:  44%|████▍     | 88/200 [00:16<00:20,  5.37epoch/s, train_loss=3.66e-6]\n",
      "Supervised training ; epochs:   2%|▏         | 3/200 [00:00<00:08, 24.19epoch/s, train_loss=0.000633]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=1.000, test=0.996) total time=  11.1s\n",
      "[CV 1/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=1.000, test=0.999) total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Supervised training ; epochs:  24%|██▍       | 48/200 [00:01<00:04, 32.35epoch/s, train_loss=2.19e-5]\r",
      "Supervised training ; epochs:  26%|██▌       | 52/200 [00:01<00:04, 31.61epoch/s, train_loss=2.19e-5]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.00148]\r",
      "Supervised training ; epochs:  34%|███▎      | 67/200 [00:02<00:04, 33.21epoch/s, train_loss=1.18e-5]\r",
      "Supervised training ; epochs:  16%|█▌        | 31/200 [00:03<00:21,  7.69epoch/s, train_loss=5.09e-5]\r",
      "Supervised training ; epochs:  16%|█▌        | 32/200 [00:03<00:21,  7.69epoch/s, train_loss=5.09e-5]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.00124]\r",
      "Supervised training ; epochs:  26%|██▌       | 52/200 [00:01<00:04, 31.61epoch/s, train_loss=2.04e-5]\r",
      "Supervised training ; epochs:   2%|▏         | 3/200 [00:00<00:08, 24.19epoch/s, train_loss=0.000468]\r",
      "Supervised training ; epochs:   3%|▎         | 6/200 [00:00<00:07, 24.99epoch/s, train_loss=0.000468]\r",
      "Supervised training ; epochs:  44%|████▍     | 88/200 [00:16<00:22,  4.95epoch/s, train_loss=8.52e-6]\r",
      "Supervised training ; epochs:  44%|████▍     | 88/200 [00:16<00:20,  5.36epoch/s, train_loss=8.52e-6]\n",
      "\r",
      "Supervised training ; epochs:  34%|███▎      | 67/200 [00:02<00:04, 33.21epoch/s, train_loss=1.14e-5]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.000966]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:06, 32.44epoch/s, train_loss=0.000966]\r",
      "Supervised training ; epochs:  26%|██▌       | 52/200 [00:01<00:04, 31.61epoch/s, train_loss=1.91e-5]\r",
      "Supervised training ; epochs:  34%|███▎      | 67/200 [00:02<00:04, 33.21epoch/s, train_loss=1.08e-5]\r",
      "Supervised training ; epochs:  36%|███▌      | 71/200 [00:02<00:04, 31.55epoch/s, train_loss=1.08e-5]\r",
      "Supervised training ; epochs:   3%|▎         | 6/200 [00:00<00:07, 24.99epoch/s, train_loss=0.000352]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.00158]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:06, 32.44epoch/s, train_loss=0.000706]\r",
      "Supervised training ; epochs:  26%|██▌       | 52/200 [00:01<00:04, 31.61epoch/s, train_loss=1.94e-5]\r",
      "Supervised training ; epochs:   3%|▎         | 6/200 [00:00<00:07, 24.99epoch/s, train_loss=0.000275]\r",
      "Supervised training ; epochs:  36%|███▌      | 71/200 [00:02<00:04, 31.55epoch/s, train_loss=9.4e-6] \r",
      "Supervised training ; epochs:  12%|█▎        | 25/200 [00:03<00:21,  7.99epoch/s, train_loss=7.83e-5]\r",
      "Supervised training ; epochs:  13%|█▎        | 26/200 [00:03<00:22,  7.70epoch/s, train_loss=7.83e-5]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.00135]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:06, 32.44epoch/s, train_loss=0.000515]\r",
      "Supervised training ; epochs:  26%|██▌       | 52/200 [00:01<00:04, 31.61epoch/s, train_loss=1.92e-5]\r",
      "Supervised training ; epochs:  28%|██▊       | 56/200 [00:01<00:04, 31.40epoch/s, train_loss=1.92e-5]\r",
      "Supervised training ; epochs:   3%|▎         | 6/200 [00:00<00:07, 24.99epoch/s, train_loss=0.000224]\r",
      "Supervised training ; epochs:   4%|▍         | 9/200 [00:00<00:07, 26.23epoch/s, train_loss=0.000224]\r",
      "Supervised training ; epochs:  36%|███▌      | 71/200 [00:02<00:04, 31.55epoch/s, train_loss=9.15e-6]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.00109]\r",
      "Supervised training ; epochs:  16%|█▌        | 32/200 [00:04<00:21,  7.69epoch/s, train_loss=4.53e-5]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:06, 32.44epoch/s, train_loss=0.000391]\r",
      "Supervised training ; epochs:  16%|█▋        | 33/200 [00:04<00:21,  7.81epoch/s, train_loss=4.53e-5]\r",
      "Supervised training ; epochs:  28%|██▊       | 56/200 [00:01<00:04, 31.40epoch/s, train_loss=1.87e-5]\r",
      "Supervised training ; epochs:   4%|▍         | 9/200 [00:00<00:07, 26.23epoch/s, train_loss=0.000189]\r",
      "Supervised training ; epochs:  36%|███▌      | 71/200 [00:02<00:04, 31.55epoch/s, train_loss=1.01e-5]\r",
      "Supervised training ; epochs:  37%|███▋      | 74/200 [00:14<00:25,  4.97epoch/s, train_loss=0.00012]\r",
      "Supervised training ; epochs:  38%|███▊      | 75/200 [00:14<00:25,  4.95epoch/s, train_loss=0.00012]\r",
      "Supervised training ; epochs:   0%|          | 0/200 [00:00<?, ?epoch/s, train_loss=0.000831]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:05, 33.06epoch/s, train_loss=0.000831]\r",
      "Supervised training ; epochs:   2%|▏         | 4/200 [00:00<00:06, 32.44epoch/s, train_loss=0.000312]\r",
      "Supervised training ; epochs:   4%|▍         | 8/200 [00:00<00:05, 32.94epoch/s, train_loss=0.000312]\r",
      "Supervised training ; epochs:  28%|██▊       | 56/200 [00:01<00:04, 31.40epoch/s, train_loss=1.75e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=1.000, test=0.996) total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  38%|███▊      | 77/200 [00:14<00:23,  5.18epoch/s, train_loss=5.29e-6] \n",
      "Supervised training ; epochs:  64%|██████▍   | 128/200 [00:04<00:02, 30.94epoch/s, train_loss=3.62e-6]\n",
      "Supervised training ; epochs:  96%|█████████▌| 192/200 [00:05<00:00, 34.25epoch/s, train_loss=1.09e-6]\n",
      "Supervised training ; epochs:  80%|████████  | 160/200 [00:04<00:01, 35.62epoch/s, train_loss=3.13e-6]\n",
      "Supervised training ; epochs:  78%|███████▊  | 156/200 [00:04<00:01, 35.00epoch/s, train_loss=2.73e-6]\n",
      "Supervised training ; epochs:  92%|█████████▏| 183/200 [00:05<00:00, 35.30epoch/s, train_loss=1.45e-6]\n",
      "Supervised training ; epochs:  46%|████▌     | 92/200 [00:09<00:10,  9.96epoch/s, train_loss=6.97e-5]\n",
      "Supervised training ; epochs:  55%|█████▌    | 110/200 [00:10<00:08, 10.87epoch/s, train_loss=1.24e-5]\n",
      "Supervised training ; epochs: 100%|█| 200/200 [00:04<00:00, 47.58epo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters randomized search : {'activation_name': 'Leaky_relu', 'alpha': 0.31622776601683794, 'batch_size': 430, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate': 0.0001972606689184097, 'optimizer_name': 'SGD', 'p_dropout': 0.26866163896885376, 'weight_decay': 0.0011453530979564342}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation_name</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_optimizer_name</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.346584</td>\n",
       "      <td>1.443283</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>Leaky_relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90</td>\n",
       "      <td>(60, 60)</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.451467</td>\n",
       "      <td>1.572430</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>Softmax</td>\n",
       "      <td>0.01</td>\n",
       "      <td>260</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.034589</td>\n",
       "      <td>SGD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997296</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.774245</td>\n",
       "      <td>1.538422</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>50</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>SGD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996755</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.065618</td>\n",
       "      <td>0.732336</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>80</td>\n",
       "      <td>(100, 50)</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>Adam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998423</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.776841</td>\n",
       "      <td>0.538071</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>Leaky_relu</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>430</td>\n",
       "      <td>(100, 50, 25)</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>SGD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997656</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      10.346584      1.443283         0.002567        0.000291   \n",
       "1       7.451467      1.572430         0.002419        0.000319   \n",
       "2      14.774245      1.538422         0.002528        0.000573   \n",
       "3      10.065618      0.732336         0.001694        0.000491   \n",
       "4       4.776841      0.538071         0.001599        0.000324   \n",
       "\n",
       "  param_activation_name param_alpha param_batch_size param_hidden_layer_sizes  \\\n",
       "0            Leaky_relu         0.1               90                 (60, 60)   \n",
       "1               Softmax        0.01              260                   (100,)   \n",
       "2                  Tanh    0.215443               50               (100, 100)   \n",
       "3               Sigmoid    0.031623               80                (100, 50)   \n",
       "4            Leaky_relu    0.316228              430            (100, 50, 25)   \n",
       "\n",
       "  param_learning_rate param_optimizer_name  ... mean_test_score  \\\n",
       "0            0.000276                 Adam  ...        0.996575   \n",
       "1            0.034589                  SGD  ...        0.997296   \n",
       "2            0.002353                  SGD  ...        0.996755   \n",
       "3            0.003585                 Adam  ...        0.996575   \n",
       "4            0.000197                  SGD  ...        0.997656   \n",
       "\n",
       "  std_test_score rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0       0.001050               5            1.000000            0.999775   \n",
       "1       0.000987               2            1.000000            1.000000   \n",
       "2       0.001223               3            1.000000            1.000000   \n",
       "3       0.001550               4            0.998873            1.000000   \n",
       "4       0.001223               1            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            1.000000            0.999549            0.998197   \n",
       "1            1.000000            1.000000            1.000000   \n",
       "2            0.998197            1.000000            1.000000   \n",
       "3            1.000000            0.998423            0.999549   \n",
       "4            1.000000            1.000000            1.000000   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.999504         0.000674  \n",
       "1          1.000000         0.000000  \n",
       "2          0.999639         0.000721  \n",
       "3          0.999369         0.000628  \n",
       "4          1.000000         0.000000  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.randomized_search(\n",
    "    param_randomized=params['randomized'],\n",
    "    n_iter=n_iter,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "407024f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 16,\n",
       " 'output_size': 1,\n",
       " 'hidden_layer_sizes': (100, 50, 25),\n",
       " 'activation_name': 'Leaky_relu',\n",
       " 'loss': 'binary_cross_entropy',\n",
       " 'optimizer_name': 'SGD',\n",
       " 'learning_rate': 0.0001972606689184097,\n",
       " 'batch_size': 430,\n",
       " 'weight_decay': 0.0011453530979564342,\n",
       " 'p_dropout': 0.26866163896885376,\n",
       " 'early_stopping': True,\n",
       " 'epochs': 200,\n",
       " 'patience': 10,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e6b9200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Supervised training ; epochs:  96%|▉| 192/200 [00:04<00:00, 44.99epo\n",
      "Semi-supervised training ; epochs:  40%|▍| 79/200 [00:01<00:02, 46.3\n",
      "/home/yanncauchepin/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_mlp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fedc829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Set - Accuracy</th>\n",
       "      <td>0.966108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - Precision</th>\n",
       "      <td>0.965755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - Recall</th>\n",
       "      <td>0.966108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - F1</th>\n",
       "      <td>0.965789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Accuracy</th>\n",
       "      <td>0.961081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Precision</th>\n",
       "      <td>0.960632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Recall</th>\n",
       "      <td>0.961081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - F1</th>\n",
       "      <td>0.960716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Scores\n",
       "Train Set - Accuracy   0.966108\n",
       "Train Set - Precision  0.965755\n",
       "Train Set - Recall     0.966108\n",
       "Train Set - F1         0.965789\n",
       "Test Set - Accuracy    0.961081\n",
       "Test Set - Precision   0.960632\n",
       "Test Set - Recall      0.961081\n",
       "Test Set - F1          0.960716"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4212cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mlp.receiver_operating_characteristics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac53482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_test = df_spark.sample(fraction=0.05, seed=30)\n",
    "df_test = df_test.dropna(subset=['loan_status'])\n",
    "features_collected = df_test.select(features).collect()\n",
    "X_test = np.array([list(feature) for feature in features_collected])\n",
    "target_collected = df_test.select('loan_status').collect()\n",
    "y_test = np.array([feature['loan_status'] for feature in target_collected])\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09624bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Set - Accuracy</th>\n",
       "      <td>0.964156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Precision</th>\n",
       "      <td>0.963724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Recall</th>\n",
       "      <td>0.964156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - F1</th>\n",
       "      <td>0.963776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Scores\n",
       "Test Set - Accuracy   0.964156\n",
       "Test Set - Precision  0.963724\n",
       "Test Set - Recall     0.964156\n",
       "Test Set - F1         0.963776"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model_performance_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13a3b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_value_collected = df_spark.sample(withReplacement=False, fraction=0.0001, seed=1).limit(1).collect()[0]\n",
    "single_value = np.array([value for key, value in single_value_collected.asDict().items() if key != 'loan_status']).reshape(1,-1).astype(float)\n",
    "single_value_target = np.array([value for key, value in single_value_collected.asDict().items() if key == 'loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7c7a098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18000.  , 12325.  , 12325.  ,     0.12,   739.  , 16341.39,\n",
       "        16341.39, 12325.  ,  4016.39,     0.  ,   271.56,   739.  ,\n",
       "          735.  ,     0.  ,     0.  ,  2016.92]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a02be47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pymnt</th>\n",
       "      <td>86.161525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>70.410990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>27.327880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>11.441951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>8.073740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <td>4.452166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <td>2.839816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <td>2.109614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rec_int</th>\n",
       "      <td>1.141622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <td>0.729925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico_range_high</th>\n",
       "      <td>0.546676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attribution\n",
       "total_pymnt_inv        100.000000\n",
       "total_pymnt             86.161525\n",
       "total_rec_prncp         70.410990\n",
       "loan_amnt               27.327880\n",
       "funded_amnt             11.441951\n",
       "funded_amnt_inv          8.073740\n",
       "last_fico_range_high     4.452166\n",
       "last_fico_range_low      2.839816\n",
       "last_pymnt_amnt          2.109614\n",
       "total_rec_int            1.141622\n",
       "last_credit_pull_d       0.729925\n",
       "fico_range_high          0.546676\n",
       "int_rate                 0.000463\n",
       "recoveries               0.000000\n",
       "mths_since_rcnt_il       0.000000\n",
       "mo_sin_old_rev_tl_op     0.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.compute_integrated_gradients(single_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0412b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=1.000, test=0.996) total time=  14.9s\n",
      "[CV 2/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=1.000, test=0.996) total time=   4.1s\n",
      "[CV 1/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=1.000, test=0.999) total time=   5.6s\n",
      "[CV 4/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=1.000, test=0.997) total time=   4.5s\n",
      "[CV 5/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=1.000, test=0.999) total time=   4.5s\n",
      "[CV 3/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=1.000, test=0.996) total time=   5.2s\n",
      "[CV 4/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=0.998, test=0.997) total time=   9.2s\n",
      "[CV 5/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=1.000, test=0.999) total time=  10.1s\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# with open('lending_club_mlp_binary_classifier.pkl', 'wb') as file:\n",
    "#     pickle.dump(model_mlp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4588f638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'int_rate',\n",
       " 'fico_range_high',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'recoveries',\n",
       " 'last_pymnt_amnt',\n",
       " 'last_fico_range_high',\n",
       " 'last_fico_range_low',\n",
       " 'mths_since_rcnt_il',\n",
       " 'mo_sin_old_rev_tl_op',\n",
       " 'last_credit_pull_d']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
