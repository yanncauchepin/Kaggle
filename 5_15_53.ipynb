{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a499894c",
   "metadata": {},
   "source": [
    "## Yann Cauchepin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfce03",
   "metadata": {},
   "source": [
    "Hi, here is my documented jupyter notebook which respond to the test request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1b09e",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Before even running the following script, please process by:\n",
    "\n",
    "- [ ] Installing the interested librairies. You can comment the next script to not bide your time.\n",
    "\n",
    "- [ ] Replacing dataset path toward your local repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a923e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /home/yanncauchepin/.local/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scipy) (1.24.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/yanncauchepin/.local/lib/python3.10/site-packages (4.64.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/yanncauchepin/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/yanncauchepin/.local/lib/python3.10/site-packages (1.24.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/yanncauchepin/.local/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in /home/yanncauchepin/.local/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: graphviz in /home/yanncauchepin/.local/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: plotly in /home/yanncauchepin/.local/lib/python3.10/site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: scipy in /home/yanncauchepin/.local/lib/python3.10/site-packages (from catboost) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from plotly->catboost) (8.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in /home/yanncauchepin/.local/lib/python3.10/site-packages (0.45.1)\n",
      "Requirement already satisfied: scipy in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (1.11.1)\n",
      "Requirement already satisfied: numba in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (4.64.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numpy in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (1.2.0)\n",
      "Requirement already satisfied: pandas in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: packaging>20.9 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (23.2)\n",
      "Requirement already satisfied: cloudpickle in /home/yanncauchepin/.local/lib/python3.10/site-packages (from shap) (2.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas->shap) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/yanncauchepin/.local/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: captum in /home/yanncauchepin/.local/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from captum) (3.5.1)\n",
      "Requirement already satisfied: tqdm in /home/yanncauchepin/.local/lib/python3.10/site-packages (from captum) (4.64.1)\n",
      "Requirement already satisfied: numpy in /home/yanncauchepin/.local/lib/python3.10/site-packages (from captum) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.6 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from captum) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch>=1.6->captum) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch>=1.6->captum) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch>=1.6->captum) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch>=1.6->captum) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from torch>=1.6->captum) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (59.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mapie in /home/yanncauchepin/.local/lib/python3.10/site-packages (0.8.6)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from mapie) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/yanncauchepin/.local/lib/python3.10/site-packages (from mapie) (23.2)\n",
      "Requirement already satisfied: scipy in /home/yanncauchepin/.local/lib/python3.10/site-packages (from mapie) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /home/yanncauchepin/.local/lib/python3.10/site-packages (from mapie) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-learn->mapie) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-learn->mapie) (1.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-optimize in /home/yanncauchepin/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-optimize) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-optimize) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in /home/yanncauchepin/.local/lib/python3.10/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yanncauchepin/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install pyspark\n",
    "!pip install catboost\n",
    "!pip install shap\n",
    "!pip install torch\n",
    "!pip install captum\n",
    "!pip install sklearn\n",
    "!pip install mapie\n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b006539",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"/media/yanncauchepin/ExternalDisk/Datasets/MachineLearningTables/lending_club/LCDataDictionary.xlsx\"\n",
    "data_path = \"/media/yanncauchepin/ExternalDisk/Datasets/MachineLearningTables/lending_club/Loan_status_2007-2020Q3.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939e91c",
   "metadata": {},
   "source": [
    "Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c14c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957f17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(metadata_path, index_col=0)\n",
    "metadata = metadata.iloc[:-2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ddf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/21 14:50:08 WARN Utils: Your hostname, yanncauchepincomputer resolves to a loopback address: 127.0.1.1; using 192.168.43.208 instead (on interface wlp2s0)\n",
      "24/06/21 14:50:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/21 14:50:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 2:================================================>        (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 2925493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LendingClubDataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_spark = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "print(f\"Number of data: {df_spark.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4751cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata features: 151\n",
      "Data features: 142\n",
      "Unknown data features: ['_c0', 'verification_status_joint', 'total_rev_hi_lim', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med'] (14)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata features: {len(metadata.index)}\")\n",
    "print(f\"Data features: {len(df_spark.columns)}\")\n",
    "\n",
    "outer_features = [feature for feature in df_spark.columns if feature not in metadata.index]\n",
    "\n",
    "print(f\"Unknown data features: {outer_features} ({len(outer_features)})\")\n",
    "df_spark = df_spark.drop(*outer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8175f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['grade', 'sub_grade']\n",
    "df_spark = df_spark.drop(*features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83763e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [feature for feature in df_spark.columns if feature != 'loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3876cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distincts values: 12 - 4.10e-06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|         loan_status|  count|\n",
      "+--------------------+-------+\n",
      "|          Fully Paid|1497783|\n",
      "|                NULL|      1|\n",
      "|     In Grace Period|  10028|\n",
      "|Does not meet the...|   1988|\n",
      "|         Charged Off| 362547|\n",
      "|  Late (31-120 days)|  16154|\n",
      "|             Current|1031016|\n",
      "|Does not meet the...|    761|\n",
      "|   Late (16-30 days)|   2719|\n",
      "|             Default|    433|\n",
      "|              Issued|   2062|\n",
      "|            Oct-2015|      1|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "value_counts = df_spark.groupBy('loan_status').count()\n",
    "value_rate = value_counts.count() / df_spark.count()\n",
    "print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b9bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mapping = {\n",
    "    'Fully Paid': 0,\n",
    "    'Charged Off': 1,\n",
    "    'Current': np.nan,\n",
    "    'Late (31-120 days)': np.nan,\n",
    "    'In Grace Period': np.nan,\n",
    "    'Late (16-30 days)': np.nan,\n",
    "    'Issued': np.nan,\n",
    "    'Does not meet the credit policy. Status:Fully Paid': np.nan,\n",
    "    'Does not meet the credit policy. Status:Charged Off': np.nan,\n",
    "    'Default': np.nan,\n",
    "    'Oct-2015': np.nan\n",
    "}\n",
    "'''\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "df_spark = df_spark.withColumn(\"loan_status\", when(df_spark[\"loan_status\"] == \"Fully Paid\", 0)\n",
    "                   .when(df_spark[\"loan_status\"] == \"Charged Off\", 1)\n",
    "                   .otherwise(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a37f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.fillna({col: \"nan\" if df_spark.schema[col].dataType == 'string' else np.nan for col in all_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205dda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distincts values: 3 - 1.03e-06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:============================================>           (11 + 3) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|loan_status|  count|\n",
      "+-----------+-------+\n",
      "|        0.0|1497783|\n",
      "|        NaN|1065163|\n",
      "|        1.0| 362547|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "value_counts = df_spark.groupBy('loan_status').count()\n",
    "value_rate = value_counts.count() / df_spark.count()\n",
    "print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83528a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('loan_amnt', 'int'),\n",
       " ('funded_amnt', 'int'),\n",
       " ('funded_amnt_inv', 'double'),\n",
       " ('term', 'string'),\n",
       " ('int_rate', 'string'),\n",
       " ('installment', 'double'),\n",
       " ('emp_title', 'string'),\n",
       " ('emp_length', 'string'),\n",
       " ('home_ownership', 'string'),\n",
       " ('annual_inc', 'string'),\n",
       " ('verification_status', 'string'),\n",
       " ('issue_d', 'string'),\n",
       " ('loan_status', 'double'),\n",
       " ('pymnt_plan', 'string'),\n",
       " ('url', 'string'),\n",
       " ('purpose', 'string'),\n",
       " ('title', 'string'),\n",
       " ('zip_code', 'string'),\n",
       " ('addr_state', 'string'),\n",
       " ('dti', 'string'),\n",
       " ('delinq_2yrs', 'double'),\n",
       " ('earliest_cr_line', 'string'),\n",
       " ('fico_range_low', 'string'),\n",
       " ('fico_range_high', 'int'),\n",
       " ('inq_last_6mths', 'int'),\n",
       " ('mths_since_last_delinq', 'int'),\n",
       " ('mths_since_last_record', 'int'),\n",
       " ('open_acc', 'int'),\n",
       " ('pub_rec', 'int'),\n",
       " ('revol_bal', 'int'),\n",
       " ('revol_util', 'string'),\n",
       " ('total_acc', 'string'),\n",
       " ('initial_list_status', 'string'),\n",
       " ('out_prncp', 'string'),\n",
       " ('out_prncp_inv', 'double'),\n",
       " ('total_pymnt', 'double'),\n",
       " ('total_pymnt_inv', 'double'),\n",
       " ('total_rec_prncp', 'double'),\n",
       " ('total_rec_int', 'double'),\n",
       " ('total_rec_late_fee', 'double'),\n",
       " ('recoveries', 'double'),\n",
       " ('collection_recovery_fee', 'double'),\n",
       " ('last_pymnt_d', 'string'),\n",
       " ('last_pymnt_amnt', 'string'),\n",
       " ('next_pymnt_d', 'string'),\n",
       " ('last_credit_pull_d', 'string'),\n",
       " ('last_fico_range_high', 'string'),\n",
       " ('last_fico_range_low', 'int'),\n",
       " ('collections_12_mths_ex_med', 'int'),\n",
       " ('mths_since_last_major_derog', 'int'),\n",
       " ('policy_code', 'int'),\n",
       " ('application_type', 'string'),\n",
       " ('annual_inc_joint', 'string'),\n",
       " ('dti_joint', 'double'),\n",
       " ('acc_now_delinq', 'int'),\n",
       " ('tot_coll_amt', 'int'),\n",
       " ('tot_cur_bal', 'int'),\n",
       " ('open_acc_6m', 'int'),\n",
       " ('open_act_il', 'int'),\n",
       " ('open_il_12m', 'int'),\n",
       " ('open_il_24m', 'int'),\n",
       " ('mths_since_rcnt_il', 'int'),\n",
       " ('total_bal_il', 'int'),\n",
       " ('il_util', 'int'),\n",
       " ('open_rv_12m', 'int'),\n",
       " ('open_rv_24m', 'int'),\n",
       " ('max_bal_bc', 'int'),\n",
       " ('all_util', 'int'),\n",
       " ('inq_fi', 'int'),\n",
       " ('total_cu_tl', 'int'),\n",
       " ('inq_last_12m', 'int'),\n",
       " ('acc_open_past_24mths', 'int'),\n",
       " ('avg_cur_bal', 'int'),\n",
       " ('bc_open_to_buy', 'int'),\n",
       " ('bc_util', 'double'),\n",
       " ('chargeoff_within_12_mths', 'double'),\n",
       " ('delinq_amnt', 'int'),\n",
       " ('mo_sin_old_il_acct', 'int'),\n",
       " ('mo_sin_old_rev_tl_op', 'int'),\n",
       " ('mo_sin_rcnt_rev_tl_op', 'int'),\n",
       " ('mo_sin_rcnt_tl', 'int'),\n",
       " ('mort_acc', 'int'),\n",
       " ('mths_since_recent_bc', 'int'),\n",
       " ('mths_since_recent_bc_dlq', 'int'),\n",
       " ('mths_since_recent_inq', 'int'),\n",
       " ('mths_since_recent_revol_delinq', 'int'),\n",
       " ('num_accts_ever_120_pd', 'int'),\n",
       " ('num_actv_bc_tl', 'int'),\n",
       " ('num_actv_rev_tl', 'int'),\n",
       " ('num_bc_sats', 'int'),\n",
       " ('num_bc_tl', 'int'),\n",
       " ('num_il_tl', 'int'),\n",
       " ('num_op_rev_tl', 'int'),\n",
       " ('num_rev_accts', 'int'),\n",
       " ('num_rev_tl_bal_gt_0', 'int'),\n",
       " ('num_sats', 'int'),\n",
       " ('num_tl_120dpd_2m', 'int'),\n",
       " ('num_tl_30dpd', 'int'),\n",
       " ('num_tl_90g_dpd_24m', 'int'),\n",
       " ('num_tl_op_past_12m', 'int'),\n",
       " ('pct_tl_nvr_dlq', 'double'),\n",
       " ('percent_bc_gt_75', 'double'),\n",
       " ('pub_rec_bankruptcies', 'int'),\n",
       " ('tax_liens', 'int'),\n",
       " ('tot_hi_cred_lim', 'int'),\n",
       " ('total_bal_ex_mort', 'int'),\n",
       " ('total_bc_limit', 'int'),\n",
       " ('total_il_high_credit_limit', 'int'),\n",
       " ('sec_app_open_act_il', 'int'),\n",
       " ('hardship_flag', 'string'),\n",
       " ('hardship_type', 'string'),\n",
       " ('hardship_reason', 'string'),\n",
       " ('hardship_status', 'string'),\n",
       " ('deferral_term', 'int'),\n",
       " ('hardship_amount', 'double'),\n",
       " ('hardship_start_date', 'string'),\n",
       " ('hardship_end_date', 'string'),\n",
       " ('payment_plan_start_date', 'string'),\n",
       " ('hardship_length', 'int'),\n",
       " ('hardship_dpd', 'int'),\n",
       " ('hardship_loan_status', 'string'),\n",
       " ('orig_projected_additional_accrued_interest', 'double'),\n",
       " ('hardship_payoff_balance_amount', 'double'),\n",
       " ('hardship_last_payment_amount', 'double'),\n",
       " ('debt_settlement_flag', 'string')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a4684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442784f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 145983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df_spark.sample(fraction=0.05, seed=1)\n",
    "print(f\"Number of data: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e255b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:============================================>           (11 + 3) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 92781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:====================================================>   (13 + 1) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['loan_status'])\n",
    "print(f\"Number of data: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1680e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/21 14:51:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features = df.select(all_features)\n",
    "features_collected = features.collect()\n",
    "target = df.select('loan_status')\n",
    "target_collected = target.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d0f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([list(feature) for feature in features_collected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee730a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([feature['loan_status'] for feature in target_collected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2387d119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92781, 125)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48cb9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92781,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a945bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feature for (feature, dtype) in df.dtypes if dtype=='string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6859dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.1319934\ttotal: 270ms\tremaining: 26.7s\n",
      "1:\tlearn: 0.0766225\ttotal: 377ms\tremaining: 18.5s\n",
      "2:\tlearn: 0.0388028\ttotal: 491ms\tremaining: 15.9s\n",
      "3:\tlearn: 0.0303303\ttotal: 570ms\tremaining: 13.7s\n",
      "4:\tlearn: 0.0235605\ttotal: 638ms\tremaining: 12.1s\n",
      "5:\tlearn: 0.0206519\ttotal: 713ms\tremaining: 11.2s\n",
      "6:\tlearn: 0.0195695\ttotal: 788ms\tremaining: 10.5s\n",
      "7:\tlearn: 0.0189217\ttotal: 853ms\tremaining: 9.81s\n",
      "8:\tlearn: 0.0175497\ttotal: 926ms\tremaining: 9.36s\n",
      "9:\tlearn: 0.0175093\ttotal: 998ms\tremaining: 8.98s\n",
      "10:\tlearn: 0.0167146\ttotal: 1.07s\tremaining: 8.68s\n",
      "11:\tlearn: 0.0158007\ttotal: 1.15s\tremaining: 8.43s\n",
      "12:\tlearn: 0.0157843\ttotal: 1.22s\tremaining: 8.15s\n",
      "13:\tlearn: 0.0123135\ttotal: 1.29s\tremaining: 7.92s\n",
      "14:\tlearn: 0.0123132\ttotal: 1.36s\tremaining: 7.72s\n",
      "15:\tlearn: 0.0120829\ttotal: 1.44s\tremaining: 7.58s\n",
      "16:\tlearn: 0.0108746\ttotal: 1.51s\tremaining: 7.38s\n",
      "17:\tlearn: 0.0108745\ttotal: 1.56s\tremaining: 7.09s\n",
      "18:\tlearn: 0.0108745\ttotal: 1.62s\tremaining: 6.91s\n",
      "19:\tlearn: 0.0108743\ttotal: 1.68s\tremaining: 6.71s\n",
      "20:\tlearn: 0.0106082\ttotal: 1.75s\tremaining: 6.58s\n",
      "21:\tlearn: 0.0105858\ttotal: 1.81s\tremaining: 6.43s\n",
      "22:\tlearn: 0.0101376\ttotal: 1.89s\tremaining: 6.32s\n",
      "23:\tlearn: 0.0099657\ttotal: 1.96s\tremaining: 6.2s\n",
      "24:\tlearn: 0.0097971\ttotal: 2.02s\tremaining: 6.07s\n",
      "25:\tlearn: 0.0097971\ttotal: 2.08s\tremaining: 5.91s\n",
      "26:\tlearn: 0.0090301\ttotal: 2.17s\tremaining: 5.86s\n",
      "27:\tlearn: 0.0088808\ttotal: 2.25s\tremaining: 5.78s\n",
      "28:\tlearn: 0.0088807\ttotal: 2.29s\tremaining: 5.6s\n",
      "29:\tlearn: 0.0088807\ttotal: 2.35s\tremaining: 5.49s\n",
      "30:\tlearn: 0.0088693\ttotal: 2.43s\tremaining: 5.41s\n",
      "31:\tlearn: 0.0088505\ttotal: 2.5s\tremaining: 5.31s\n",
      "32:\tlearn: 0.0088505\ttotal: 2.55s\tremaining: 5.18s\n",
      "33:\tlearn: 0.0088279\ttotal: 2.62s\tremaining: 5.09s\n",
      "34:\tlearn: 0.0088216\ttotal: 2.69s\tremaining: 5s\n",
      "35:\tlearn: 0.0087373\ttotal: 2.76s\tremaining: 4.91s\n",
      "36:\tlearn: 0.0078413\ttotal: 2.83s\tremaining: 4.83s\n",
      "37:\tlearn: 0.0078412\ttotal: 2.89s\tremaining: 4.71s\n",
      "38:\tlearn: 0.0066885\ttotal: 2.97s\tremaining: 4.64s\n",
      "39:\tlearn: 0.0066885\ttotal: 3.02s\tremaining: 4.54s\n",
      "40:\tlearn: 0.0065157\ttotal: 3.09s\tremaining: 4.45s\n",
      "41:\tlearn: 0.0064130\ttotal: 3.16s\tremaining: 4.37s\n",
      "42:\tlearn: 0.0063812\ttotal: 3.23s\tremaining: 4.29s\n",
      "43:\tlearn: 0.0063812\ttotal: 3.29s\tremaining: 4.19s\n",
      "44:\tlearn: 0.0063309\ttotal: 3.36s\tremaining: 4.11s\n",
      "45:\tlearn: 0.0062925\ttotal: 3.43s\tremaining: 4.02s\n",
      "46:\tlearn: 0.0061442\ttotal: 3.5s\tremaining: 3.95s\n",
      "47:\tlearn: 0.0061000\ttotal: 3.57s\tremaining: 3.87s\n",
      "48:\tlearn: 0.0060704\ttotal: 3.64s\tremaining: 3.79s\n",
      "49:\tlearn: 0.0060494\ttotal: 3.7s\tremaining: 3.7s\n",
      "50:\tlearn: 0.0060438\ttotal: 3.77s\tremaining: 3.63s\n",
      "51:\tlearn: 0.0056426\ttotal: 3.84s\tremaining: 3.55s\n",
      "52:\tlearn: 0.0055848\ttotal: 3.91s\tremaining: 3.47s\n",
      "53:\tlearn: 0.0055847\ttotal: 3.96s\tremaining: 3.38s\n",
      "54:\tlearn: 0.0055030\ttotal: 4.04s\tremaining: 3.31s\n",
      "55:\tlearn: 0.0054123\ttotal: 4.11s\tremaining: 3.23s\n",
      "56:\tlearn: 0.0050235\ttotal: 4.19s\tremaining: 3.16s\n",
      "57:\tlearn: 0.0047845\ttotal: 4.27s\tremaining: 3.09s\n",
      "58:\tlearn: 0.0047173\ttotal: 4.34s\tremaining: 3.02s\n",
      "59:\tlearn: 0.0047172\ttotal: 4.4s\tremaining: 2.94s\n",
      "60:\tlearn: 0.0046941\ttotal: 4.48s\tremaining: 2.86s\n",
      "61:\tlearn: 0.0046940\ttotal: 4.54s\tremaining: 2.79s\n",
      "62:\tlearn: 0.0046540\ttotal: 4.61s\tremaining: 2.71s\n",
      "63:\tlearn: 0.0046535\ttotal: 4.68s\tremaining: 2.63s\n",
      "64:\tlearn: 0.0046141\ttotal: 4.76s\tremaining: 2.56s\n",
      "65:\tlearn: 0.0045433\ttotal: 4.83s\tremaining: 2.49s\n",
      "66:\tlearn: 0.0044677\ttotal: 4.89s\tremaining: 2.41s\n",
      "67:\tlearn: 0.0044677\ttotal: 4.96s\tremaining: 2.33s\n",
      "68:\tlearn: 0.0043488\ttotal: 5.04s\tremaining: 2.26s\n",
      "69:\tlearn: 0.0042946\ttotal: 5.11s\tremaining: 2.19s\n",
      "70:\tlearn: 0.0042359\ttotal: 5.18s\tremaining: 2.12s\n",
      "71:\tlearn: 0.0042071\ttotal: 5.25s\tremaining: 2.04s\n",
      "72:\tlearn: 0.0041746\ttotal: 5.33s\tremaining: 1.97s\n",
      "73:\tlearn: 0.0041202\ttotal: 5.4s\tremaining: 1.9s\n",
      "74:\tlearn: 0.0041200\ttotal: 5.46s\tremaining: 1.82s\n",
      "75:\tlearn: 0.0040684\ttotal: 5.54s\tremaining: 1.75s\n",
      "76:\tlearn: 0.0040683\ttotal: 5.6s\tremaining: 1.67s\n",
      "77:\tlearn: 0.0040164\ttotal: 5.67s\tremaining: 1.6s\n",
      "78:\tlearn: 0.0039820\ttotal: 5.75s\tremaining: 1.53s\n",
      "79:\tlearn: 0.0039598\ttotal: 5.82s\tremaining: 1.46s\n",
      "80:\tlearn: 0.0039597\ttotal: 5.88s\tremaining: 1.38s\n",
      "81:\tlearn: 0.0039349\ttotal: 5.95s\tremaining: 1.31s\n",
      "82:\tlearn: 0.0039181\ttotal: 6.03s\tremaining: 1.23s\n",
      "83:\tlearn: 0.0038998\ttotal: 6.09s\tremaining: 1.16s\n",
      "84:\tlearn: 0.0038938\ttotal: 6.15s\tremaining: 1.08s\n",
      "85:\tlearn: 0.0038823\ttotal: 6.22s\tremaining: 1.01s\n",
      "86:\tlearn: 0.0038823\ttotal: 6.29s\tremaining: 939ms\n",
      "87:\tlearn: 0.0038822\ttotal: 6.35s\tremaining: 866ms\n",
      "88:\tlearn: 0.0038421\ttotal: 6.42s\tremaining: 794ms\n",
      "89:\tlearn: 0.0037379\ttotal: 6.5s\tremaining: 722ms\n",
      "90:\tlearn: 0.0037174\ttotal: 6.57s\tremaining: 650ms\n",
      "91:\tlearn: 0.0037173\ttotal: 6.63s\tremaining: 577ms\n",
      "92:\tlearn: 0.0036843\ttotal: 6.71s\tremaining: 505ms\n",
      "93:\tlearn: 0.0036596\ttotal: 6.77s\tremaining: 432ms\n",
      "94:\tlearn: 0.0036312\ttotal: 6.84s\tremaining: 360ms\n",
      "95:\tlearn: 0.0036311\ttotal: 6.91s\tremaining: 288ms\n",
      "96:\tlearn: 0.0036191\ttotal: 6.97s\tremaining: 216ms\n",
      "97:\tlearn: 0.0036191\ttotal: 7.03s\tremaining: 144ms\n",
      "98:\tlearn: 0.0036137\ttotal: 7.11s\tremaining: 71.8ms\n",
      "99:\tlearn: 0.0035804\ttotal: 7.18s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x775a185c87c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "pool = Pool(data=X, label=y, feature_names=all_features, cat_features=categorical_features)\n",
    "\n",
    "catboost_model = CatBoostClassifier(iterations=100)\n",
    "catboost_model.fit(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbc2cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(catboost_model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8587e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>417046.553348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>149158.378179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <td>135989.706385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>128005.130072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>93815.640670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <td>1.477193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico_range_low</th>\n",
       "      <td>0.305097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>0.073228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_flag</th>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature_importance\n",
       "total_rec_prncp            417046.553348\n",
       "recoveries                 149158.378179\n",
       "last_fico_range_low        135989.706385\n",
       "loan_amnt                  128005.130072\n",
       "funded_amnt_inv             93815.640670\n",
       "...                                  ...\n",
       "hardship_loan_status            1.477193\n",
       "fico_range_low                  0.305097\n",
       "open_acc_6m                     0.073228\n",
       "verification_status             0.000302\n",
       "hardship_flag                   0.000125\n",
       "\n",
       "[106 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_over_feature = np.sum(np.abs(shap_values), axis=0)\n",
    "feature_importance = pd.DataFrame(data=sum_over_feature, index=all_features, columns=['feature_importance'])\n",
    "feature_importance = feature_importance[feature_importance['feature_importance']>0]\n",
    "feature_importance = feature_importance.sort_values(by='feature_importance', ascending=False)\n",
    "feature_importance.shape\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39cbd894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>417046.553348</td>\n",
       "      <td>4.170466e+05</td>\n",
       "      <td>0.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>149158.378179</td>\n",
       "      <td>5.662049e+05</td>\n",
       "      <td>0.411007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <td>135989.706385</td>\n",
       "      <td>7.021946e+05</td>\n",
       "      <td>0.509721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>128005.130072</td>\n",
       "      <td>8.301998e+05</td>\n",
       "      <td>0.602640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>93815.640670</td>\n",
       "      <td>9.240154e+05</td>\n",
       "      <td>0.670740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <td>1.477193</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico_range_low</th>\n",
       "      <td>0.305097</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>0.073228</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardship_flag</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.377605e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature_importance  cumulative_sum      rate\n",
       "total_rec_prncp            417046.553348    4.170466e+05  0.302733\n",
       "recoveries                 149158.378179    5.662049e+05  0.411007\n",
       "last_fico_range_low        135989.706385    7.021946e+05  0.509721\n",
       "loan_amnt                  128005.130072    8.301998e+05  0.602640\n",
       "funded_amnt_inv             93815.640670    9.240154e+05  0.670740\n",
       "...                                  ...             ...       ...\n",
       "hardship_loan_status            1.477193    1.377605e+06  1.000000\n",
       "fico_range_low                  0.305097    1.377605e+06  1.000000\n",
       "open_acc_6m                     0.073228    1.377605e+06  1.000000\n",
       "verification_status             0.000302    1.377605e+06  1.000000\n",
       "hardship_flag                   0.000125    1.377605e+06  1.000000\n",
       "\n",
       "[106 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance['cumulative_sum'] = feature_importance['feature_importance'].cumsum()\n",
    "total_sum = feature_importance['feature_importance'].sum()\n",
    "feature_importance['rate'] = feature_importance['cumulative_sum'] / total_sum\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bdd2694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "selected_features = feature_importance[feature_importance['rate'] < threshold].index\n",
    "selected_features\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d8b87fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = [feature for feature in all_features if feature not in selected_features]\n",
    "features_to_drop\n",
    "len(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de6d755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(*features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dbace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "to_float_udf = udf(to_float, FloatType())\n",
    "df_spark = df_spark.withColumn(\"last_fico_range_high\", to_float_udf(df_spark[\"last_fico_range_high\"]))\n",
    "df_spark = df_spark.withColumn(\"last_pymnt_amnt\", to_float_udf(df_spark[\"last_pymnt_amnt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8720722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView(\"lending_club\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8de72519",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_expression = \"\"\"\n",
    "CASE\n",
    "    WHEN last_pymnt_d LIKE 'Jan-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 0/12\n",
    "    WHEN last_pymnt_d LIKE 'Feb-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 1/12\n",
    "    WHEN last_pymnt_d LIKE 'Mar-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 2/12\n",
    "    WHEN last_pymnt_d LIKE 'Apr-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 3/12\n",
    "    WHEN last_pymnt_d LIKE 'May-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 4/12\n",
    "    WHEN last_pymnt_d LIKE 'Jun-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 5/12\n",
    "    WHEN last_pymnt_d LIKE 'Jul-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 6/12\n",
    "    WHEN last_pymnt_d LIKE 'Aug-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 7/12\n",
    "    WHEN last_pymnt_d LIKE 'Sep-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 8/12\n",
    "    WHEN last_pymnt_d LIKE 'Oct-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 9/12\n",
    "    WHEN last_pymnt_d LIKE 'Nov-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 10/12\n",
    "    WHEN last_pymnt_d LIKE 'Dec-%' THEN CAST(SUBSTRING(last_pymnt_d, 5) AS FLOAT) + 11/12\n",
    "    ELSE NULL\n",
    "END AS last_pymnt_d_num\n",
    "\"\"\"\n",
    "df_spark = spark.sql(f\"\"\"\n",
    "SELECT *, {sql_expression}\n",
    "FROM lending_club\n",
    "\"\"\")\n",
    "\n",
    "df_spark = df_spark.drop(\"last_pymnt_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_pymnt_d_num', 'last_pymnt_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a41c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_expression = \"\"\"\n",
    "CASE\n",
    "    WHEN last_credit_pull_d LIKE 'Jan-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 0/12\n",
    "    WHEN last_credit_pull_d LIKE 'Feb-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 1/12\n",
    "    WHEN last_credit_pull_d LIKE 'Mar-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 2/12\n",
    "    WHEN last_credit_pull_d LIKE 'Apr-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 3/12\n",
    "    WHEN last_credit_pull_d LIKE 'May-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 4/12\n",
    "    WHEN last_credit_pull_d LIKE 'Jun-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 5/12\n",
    "    WHEN last_credit_pull_d LIKE 'Jul-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 6/12\n",
    "    WHEN last_credit_pull_d LIKE 'Aug-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 7/12\n",
    "    WHEN last_credit_pull_d LIKE 'Sep-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 8/12\n",
    "    WHEN last_credit_pull_d LIKE 'Oct-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 9/12\n",
    "    WHEN last_credit_pull_d LIKE 'Nov-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 10/12\n",
    "    WHEN last_credit_pull_d LIKE 'Dec-%' THEN CAST(SUBSTRING(last_credit_pull_d, 5) AS FLOAT) + 11/12\n",
    "    ELSE NULL\n",
    "END AS last_credit_pull_d_num\n",
    "\"\"\"\n",
    "df_spark = spark.sql(f\"\"\"\n",
    "SELECT *, {sql_expression}\n",
    "FROM lending_club\n",
    "\"\"\")\n",
    "\n",
    "df_spark = df_spark.drop(\"last_credit_pull_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_credit_pull_d_num', 'last_credit_pull_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ddc7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(\"last_pymnt_d\")\n",
    "df_spark = df_spark.withColumnRenamed('last_pymnt_d_num', 'last_pymnt_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a3645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_float_rate = udf(lambda x: float(x.replace('%', '')) / 100, FloatType())\n",
    "df_spark = df_spark.withColumn('int_rate', convert_to_float_rate(df_spark['int_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab30efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "numerical_selected_features = [feature for (feature, dtype) in df_spark.dtypes if (dtype!='string' and feature !='loan_status')]\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=numerical_selected_features,\n",
    "    outputCols=numerical_selected_features\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "df_spark = imputer.fit(df_spark).transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a751f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark.sql.functions import isnan\\nfor feature, dtype in df_spark.dtypes:\\n    print(\"====================================\")\\n    print(f\"FEATURE: {feature}\")\\n    if dtype==\\'string\\':\\n        value_counts = df_spark.groupBy(feature).count()\\n        value_rate = value_counts.count() / df_spark.count()\\n        print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\\n        value_counts.show()\\n    nan_count = df_spark.filter(df_spark[feature].isNull() | isnan(df_spark[feature])).count()\\n    nan_rate = nan_count / df_spark.count()\\n    print(f\"{nan_count} NaN - {nan_rate:.2e} %\")\\n    print(\"\\n\")'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pyspark.sql.functions import isnan\n",
    "for feature, dtype in df_spark.dtypes:\n",
    "    print(\"====================================\")\n",
    "    print(f\"FEATURE: {feature}\")\n",
    "    if dtype=='string':\n",
    "        value_counts = df_spark.groupBy(feature).count()\n",
    "        value_rate = value_counts.count() / df_spark.count()\n",
    "        print(f\"Number of distincts values: {value_counts.count()} - {value_rate:.2e} %\")\n",
    "        value_counts.show()\n",
    "    nan_count = df_spark.filter(df_spark[feature].isNull() | isnan(df_spark[feature])).count()\n",
    "    nan_rate = nan_count / df_spark.count()\n",
    "    print(f\"{nan_count} NaN - {nan_rate:.2e} %\")\n",
    "    print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f79120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 14518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df_spark.sample(fraction=0.005, seed=1)\n",
    "print(f\"Number of data: {df.count()}\")\n",
    "df = df.dropna(subset=['loan_status'])\n",
    "print(f\"Number of data: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "756ac9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features = [feature for feature in list(df_spark.columns) if feature != 'loan_status']\n",
    "features_collected = df.select(features).collect()\n",
    "target_collected = df.select('loan_status').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8eb7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([list(feature) for feature in features_collected])\n",
    "y = np.array([feature['loan_status'] for feature in target_collected])\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b383f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3b5568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from captum.attr import IntegratedGradients\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from mapie.classification import MapieClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from skopt import BayesSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layer_sizes, activation_name, p_dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        if isinstance(self.hidden_layer_sizes, str):\n",
    "            self.hidden_layer_sizes = eval(self.hidden_layer_sizes)\n",
    "        self.activation_name = activation_name\n",
    "        self.p_dropout = p_dropout\n",
    "        if activation_name == \"Relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_name == \"Sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation_name == \"Softmax\":\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        elif activation_name == \"Tanh\":\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation_name == \"Leaky_relu\":\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported activation: {self.activation_name}')\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.input_size, self.hidden_layer_sizes[0]))\n",
    "        layers.append(self.activation)\n",
    "        for i in range(len(self.hidden_layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(self.hidden_layer_sizes[i], self.hidden_layer_sizes[i + 1]))\n",
    "            layers.append(self.activation)\n",
    "            layers.append(nn.Dropout(p=self.p_dropout))\n",
    "        layers.append(nn.Linear(self.hidden_layer_sizes[-1], self.output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward_proba(self, X):\n",
    "        output = self.model(X)\n",
    "        output = self.output_activation(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.model(X)\n",
    "        output = self.output_activation(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MLPEstimatorSklearn():\n",
    "    def __init__(self, **params):\n",
    "        self.input_size = params.get(\"input_size\")\n",
    "        self.output_size = params.get(\"output_size\")\n",
    "        self.hidden_layer_sizes = params.get(\"hidden_layer_sizes\", (60, 60))\n",
    "        self.activation_name = params.get(\"activation_name\", \"Relu\")\n",
    "        self.loss = params.get(\"loss\", \"binary_cross_entropy\")\n",
    "        self.optimizer_name = params.get(\"optimizer_name\", \"Adam\")\n",
    "        self.learning_rate = params.get(\"learning_rate\", 1e-3)\n",
    "        self.batch_size = params.get(\"batch_size\", 50)\n",
    "        self.weight_decay = params.get(\"weight_decay\", 0)\n",
    "        self.p_dropout = params.get(\"p_dropout\", 0.2)\n",
    "        self.early_stopping = params.get(\"early_stopping\", True)\n",
    "        self.epochs = params.get(\"epochs\", 200)\n",
    "        self.patience = params.get(\"patience\", 10)\n",
    "        self.verbose = params.get(\"verbose\", True)\n",
    "        self.classes_ = classes_\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = MLP(self.input_size, self.output_size, self.hidden_layer_sizes, self.activation_name, self.p_dropout).to(self.device)\n",
    "\n",
    "        if self.loss == \"binary_cross_entropy\":\n",
    "            self.criterion = nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported loss: {self.loss}\")\n",
    "\n",
    "        if self.optimizer_name == \"SGD\":\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=self.weight_decay)\n",
    "        elif self.optimizer_name == \"Adam\":\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {self.optimizer}\")\n",
    "            \n",
    "    def next_batch(self, inputs, targets, batchSize):\n",
    "        inputs_np = inputs.values if isinstance(inputs, pd.DataFrame) else inputs\n",
    "        targets_np = targets.values if isinstance(targets, pd.DataFrame) else targets\n",
    "        inputs_tensor = torch.from_numpy(inputs_np).float()\n",
    "        targets_tensor = torch.from_numpy(targets_np).float().squeeze()\n",
    "        for i in range(0, inputs_tensor.shape[0], batchSize):\n",
    "            yield (inputs_tensor[i:i + batchSize], targets_tensor[i:i + batchSize])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        running_losses = list()\n",
    "        if self.early_stopping:\n",
    "            best_loss = float('inf')\n",
    "            count = 0\n",
    "        if self.verbose:\n",
    "            epoch_iterator = tqdm(range(self.epochs), desc=\"Training Epochs\", unit=\"epoch\")\n",
    "        else:\n",
    "            epoch_iterator = range(self.epochs)\n",
    "        for epoch in epoch_iterator:\n",
    "            samples = 0\n",
    "            train_loss = 0.0\n",
    "            self.model.train(True)\n",
    "            for i, (batchX, batchY) in enumerate(self.next_batch(X, y, self.batch_size)):\n",
    "                batchX = batchX.to(self.device)\n",
    "                batchY = batchY.to(self.device)\n",
    "                batchY.requires_grad = True\n",
    "                print(f\"##########{batchY.shape}\")\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(batchX)\n",
    "                loss = self.criterion(outputs, batchY)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                samples += batchY.size(0)\n",
    "            running_loss = train_loss / samples\n",
    "            running_losses.append(running_loss)\n",
    "            if self.verbose:\n",
    "                epoch_iterator.set_postfix(train_loss=running_loss)\n",
    "            if self.early_stopping:\n",
    "                if running_loss < best_loss:\n",
    "                    best_loss = running_loss\n",
    "                    count = 0\n",
    "                else:\n",
    "                    count += 1\n",
    "                if count >= self.patience:\n",
    "                    #print(\"Early stopping due to no improvement in loss.\")\n",
    "                    break\n",
    "        if self.verbose:\n",
    "            epoch_iterator.close()\n",
    "        self.running_losses = [loss for loss in running_losses if loss <= best_loss]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X = torch.from_numpy(X).float().to(self.device)\n",
    "        y_pred = self.model.forward(X)\n",
    "        if self.device == \"cpu\":\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "        else:\n",
    "            y_pred = y_pred.detach().numpy()\n",
    "        return y_pred.astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        X = torch.from_numpy(X).float().to(self.device)\n",
    "        y_proba = self.model.forward_proba(X)\n",
    "        if self.device == \"cpu\":\n",
    "            y_proba = y_proba.cpu().detach().numpy()\n",
    "        else:\n",
    "            y_proba = y_proba.detach().numpy()\n",
    "        return y_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = {\n",
    "            \"input_size\": self.input_size,\n",
    "            \"output_size\": self.output_size,\n",
    "            \"hidden_layer_sizes\": self.hidden_layer_sizes,\n",
    "            \"activation_name\": self.activation_name,\n",
    "            \"loss\": self.loss,\n",
    "            \"optimizer_name\": self.optimizer_name,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"p_dropout\": self.p_dropout,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"patience\": self.patience,\n",
    "            \"verbose\": self.verbose\n",
    "        }\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "class MLPBinaryClassifier():\n",
    "    def __init__(self, X, y, split_test, **params):\n",
    "        self.model = MLPEstimatorSklearn(**params)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.y = MLPBinaryClassifier.float_to_class(self.y).ravel()\n",
    "        \n",
    "        self.split_test = split_test\n",
    "        self.split_data()\n",
    "        \n",
    "        self.standardize(self.X_train)\n",
    "        self.X_train_standard = self.standardize_X(self.X_train)\n",
    "        self.y_train_standard = self.y_train\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def float_to_class(y):\n",
    "        threshold = 0.5\n",
    "        return (y >= threshold).astype(int)\n",
    "    \n",
    "    def split_data(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=self.split_test, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "    def standardize(self, X):\n",
    "        self.scaler_X_train = StandardScaler()\n",
    "        self.scaler_X_train.fit(X)         \n",
    "\n",
    "\n",
    "    def standardize_X(self, X):\n",
    "        X_new = self.scaler_X_train.transform(X)\n",
    "        return X_new\n",
    "    \n",
    "\n",
    "\n",
    "    def bayes_search(self, param_bayes, n_iter, n_points=1, cv=5, scoring='accuracy',\n",
    "                 verbose=3, n_jobs=1) :\n",
    "        cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "        bayes_search = BayesSearchCV(self.model, param_bayes, n_iter=n_iter,\n",
    "                                     n_points=n_points, cv=cv, scoring=scoring,\n",
    "                                     verbose=verbose, return_train_score=True,\n",
    "                                     n_jobs=n_jobs, random_state=1)\n",
    "        bayes_search.fit(self.X_train_standard, self.y_train_standard)\n",
    "        results_df = pd.DataFrame(bayes_search.cv_results_)\n",
    "        self.model = bayes_search.best_estimator_\n",
    "        print(f'Best hyperparameters bayes search : {bayes_search.best_params_}')\n",
    "        return results_df\n",
    "\n",
    "    def randomized_search(self, param_randomized, n_iter, cv=5, scoring='accuracy',\n",
    "                      verbose=3, n_jobs=1) :\n",
    "        cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "        randomized_search = RandomizedSearchCV(self.model, param_randomized,\n",
    "                                               n_iter=n_iter, cv=cv, scoring=scoring,\n",
    "                                               verbose=verbose, return_train_score=True,\n",
    "                                               n_jobs=n_jobs, random_state=1)\n",
    "        randomized_search.fit(self.X_train_standard, self.y_train_standard)\n",
    "        results_df = pd.DataFrame(randomized_search.cv_results_)\n",
    "        self.model = randomized_search.best_estimator_\n",
    "        print(f'Best hyperparameters randomized search : {randomized_search.best_params_}')\n",
    "        return results_df\n",
    "\n",
    "    def fit(self):\n",
    "        self.model.fit(self.X_train_standard, self.y_train_standard)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_standard = self.standardize_X(X)\n",
    "        y_pred = self.model.predict(X_standard)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_standard = self.standardize_X(X)\n",
    "        y_proba = self.model.predict_proba(X_standard)\n",
    "        y_proba = np.array([self.unstandardize_y(item) for item in y_proba])\n",
    "        return y_proba\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_metrics(metric, y_true, y_pred):\n",
    "        y_pred = MLPBinaryClassifier.float_to_class(y_pred)\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "        precision = metrics.precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall = metrics.recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "        metrics_dict = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "        }\n",
    "        if metric != 'all':\n",
    "            metrics_dict = {metric: metrics_dict[metric]}\n",
    "        return metrics_dict\n",
    "\n",
    "\n",
    "    def model_performance(self, metric='all'):\n",
    "        y_pred_train = self.predict(self.X_train)\n",
    "        scores_train = MLPBinaryClassifier.compute_metrics(metric, self.y_train, y_pred_train)\n",
    "        y_pred_test = self.predict(self.X_test)\n",
    "        scores_test = MLPBinaryClassifier.compute_metrics(metric, self.y_test, y_pred_test)\n",
    "        data = {}\n",
    "        for key, value in scores_train.items():\n",
    "            data['Train Set - '+key] = [value]\n",
    "        for key, value in scores_test.items():\n",
    "            data['Test Set - '+key] = [value]\n",
    "        df_scores = pd.DataFrame(data=data).T\n",
    "        df_scores.columns = ['Scores']\n",
    "        return df_scores\n",
    "\n",
    "    def model_performance_test(self, X_test, y_test, metric='all'):\n",
    "        y_pred_test = self.predict(X_test)\n",
    "        scores_test = MLPBinaryClassifier.compute_metrics(metric, y_test, y_pred_test)\n",
    "        data = {}\n",
    "        for key, value in scores_test.items():\n",
    "            data['Test Set - '+key] = [value]\n",
    "        df_scores = pd.DataFrame(data=data).T\n",
    "        df_scores.columns = ['Scores']\n",
    "        return df_scores\n",
    "\n",
    "    def receiver_operating_characteristics(self):\n",
    "        y_pred_test = self.predict(self.X_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(self.y_test, y_pred_test)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(\"Receiver Operating Characteristics\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.show()\n",
    "\n",
    "    def compute_integrated_gradients(self, X, baseline=None, steps=50):\n",
    "        def preprocess_input(X):\n",
    "            return torch.tensor(X, dtype=torch.float32)\n",
    "        input_tensor = preprocess_input(X)\n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(input_tensor)\n",
    "        integrated_gradients = IntegratedGradients(self.model.get_model())\n",
    "        attributions = integrated_gradients.attribute(input_tensor, baseline, target=0, n_steps=steps)\n",
    "        attributions_df = pd.DataFrame(attributions.cpu().detach().numpy(), columns=features)\n",
    "        avg_attributions = attributions_df.mean(axis=0)\n",
    "        sorted_attributions = avg_attributions.sort_values(ascending=False)\n",
    "        return sorted_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab236126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "from skopt.space import Real\n",
    "\n",
    "\n",
    "params = {    \n",
    "    \"init\" : {\n",
    "        \"input_size\" : len(features),\n",
    "        \"output_size\" : 1,\n",
    "        \"hidden_layer_sizes\" : (60,60),\n",
    "        \"activation_name\" : \"Relu\",\n",
    "        \"optimizer_name\" : \"Adam\",\n",
    "        \"learning_rate\" : 1e-3,\n",
    "        \"batch_size\" : 50,\n",
    "        \"weight_decay\" : 0,\n",
    "        \"p_dropout\" : 0.3,\n",
    "        \"loss\" : \"binary_cross_entropy\",\n",
    "        \"early_stopping\" : True,\n",
    "        \"epochs\" : 200,\n",
    "        \"patience\" : 10,\n",
    "        \"verbose\" : True\n",
    "    },\n",
    "    \"randomized\": {\n",
    "        \"hidden_layer_sizes\" : [(10,),(50,),(100,),(10,10),(50,50),(60,60),(100,50),(100,100),(100,50,25)],\n",
    "        \"activation_name\" :  [\"Relu\", \"Sigmoid\", \"Tanh\", \"Leaky_relu\", \"Softmax\"],\n",
    "        \"learning_rate\" : loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\" : list(np.arange(10,500, 10)),\n",
    "        \"optimizer_name\" : [\"Adam\", \"SGD\"],\n",
    "        \"alpha\" : np.logspace(-3,0,19),\n",
    "        \"weight_decay\" : loguniform(1e-5, 1),\n",
    "        \"p_dropout\" : uniform(0, 0.4)   \n",
    "    },\n",
    "    \"bayes\": {\n",
    "        \"hidden_layer_sizes\" : [\"(10,)\",\"(50,)\",\"(100,)\",\"(10,10)\",\"(50,50)\",\"(60,60)\",\"(100,50)\",\"(100,100)\",\"(100,50,25)\"],\n",
    "        \"activation_name\" :  [\"Relu\", \"Sigmoid\", \"Tanh\", \"Leaky_relu\", \"Softmax\"],\n",
    "        \"learning_rate\" : Real(1e-4, 1e-1, prior='log-uniform'),\n",
    "        \"batch_size\" : list(np.arange(10,500, 10)),\n",
    "        \"optimizer_name\" : [\"Adam\", \"SGD\"],\n",
    "        \"alpha\" : np.logspace(-3,0,19),\n",
    "        \"weight_decay\" : Real(1e-5, 1, prior='log-uniform'),\n",
    "        \"p_dropout\" : Real(0, 0.4, prior='uniform')\n",
    "    }\n",
    "}\n",
    "y = y.reshape(-1,1)\n",
    "model_mlp = MLPBinaryClassifier(X=X, y=y, split_test=0.2, **params[\"init\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02818466",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5\n",
    "n_points=1\n",
    "cv=5\n",
    "scoring='accuracy'\n",
    "verbose=3\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5845bfef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbayes_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_bayes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbayes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 251\u001b[0m, in \u001b[0;36mMLPBinaryClassifier.bayes_search\u001b[0;34m(self, param_bayes, n_iter, n_points, cv, scoring, verbose, n_jobs)\u001b[0m\n\u001b[1;32m    246\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mcv, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m bayes_search \u001b[38;5;241m=\u001b[39m BayesSearchCV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, param_bayes, n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[1;32m    248\u001b[0m                              n_points\u001b[38;5;241m=\u001b[39mn_points, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[1;32m    249\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39mverbose, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    250\u001b[0m                              n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m \u001b[43mbayes_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train_standard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bayes_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m bayes_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:400\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[1;32m    403\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:395\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    393\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points):\n\u001b[0;32m--> 395\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    398\u001b[0m     ti_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(opt\u001b[38;5;241m.\u001b[39myi) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query point or multiple points at which objective should be evaluated.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03mn_points : int or None, default: None\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m supported_strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_max\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(n_points, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m n_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:434\u001b[0m, in \u001b[0;36mOptimizer._ask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_estimator_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# this will not make a copy of `self.rng` and hence keep advancing\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# our random state.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;66;03m# The samples are evaluated starting form initial_samples[0]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples[\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/space.py:900\u001b[0m, in \u001b[0;36mSpace.rvs\u001b[0;34m(self, n_samples, random_state)\u001b[0m\n\u001b[1;32m    897\u001b[0m columns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions:\n\u001b[0;32m--> 900\u001b[0m     columns\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# Transpose\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _transpose_list_array(columns)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/space.py:698\u001b[0m, in \u001b[0;36mCategorical.rvs\u001b[0;34m(self, n_samples, random_state)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_transform([(choices)])\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/space.py:685\u001b[0m, in \u001b[0;36mCategorical.inverse_transform\u001b[0;34m(self, Xt)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03m   original space.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# The concatenation of all transformed dimensions makes Xt to be\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# of type float, hence the required cast back to int.\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m inv_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inv_transform, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    687\u001b[0m     inv_transform \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(inv_transform)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/space.py:168\u001b[0m, in \u001b[0;36mDimension.inverse_transform\u001b[0;34m(self, Xt)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xt):\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m       original space.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/transformers.py:309\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transformer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 309\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/space/transformers.py:275\u001b[0m, in \u001b[0;36mNormalize.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    273\u001b[0m X_orig \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_int:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(X_orig)\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_orig\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# model_mlp.bayes_search(\n",
    "#     param_bayes=params['bayes'],\n",
    "#     n_iter=n_iter,\n",
    "#     n_points=n_points,\n",
    "#     cv=cv,\n",
    "#     scoring=scoring,\n",
    "#     n_jobs=n_jobs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d63527ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|███▉      | 79/200 [00:05<00:08, 13.88epoch/s, train_loss=8.55e-6] \n",
      "\n",
      "\n",
      "Training Epochs:  23%|██▎       | 46/200 [00:06<00:23,  6.67epoch/s, train_loss=3.01e-5]\n",
      "\n",
      "Training Epochs:  16%|█▋        | 33/200 [00:06<00:32,  5.09epoch/s, train_loss=3.77e-5]\n",
      "Training Epochs:  42%|████▏     | 83/200 [00:06<00:08, 13.37epoch/s, train_loss=6.58e-6]\n",
      "Training Epochs:  39%|███▉      | 78/200 [00:06<00:09, 12.67epoch/s, train_loss=6.41e-6]\n",
      "Training Epochs:   0%|          | 1/200 [00:00<00:45,  4.40epoch/s, train_loss=0.0068]5]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandomized_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_randomized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandomized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 257\u001b[0m, in \u001b[0;36mMLPBinaryClassifier.randomized_search\u001b[0;34m(self, param_randomized, n_iter, cv, scoring, verbose, n_jobs)\u001b[0m\n\u001b[1;32m    252\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mcv, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    253\u001b[0m randomized_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, param_randomized,\n\u001b[1;32m    254\u001b[0m                                        n_iter\u001b[38;5;241m=\u001b[39mn_iter, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[1;32m    255\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    256\u001b[0m                                        n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 257\u001b[0m \u001b[43mrandomized_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train_standard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(randomized_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m randomized_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1769\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1769\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_mlp.randomized_search(\n",
    "    param_randomized=params['randomized'],\n",
    "    n_iter=n_iter,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "407024f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 16,\n",
       " 'output_size': 1,\n",
       " 'hidden_layer_sizes': (100, 100),\n",
       " 'activation_name': 'Tanh',\n",
       " 'loss': 'binary_cross_entropy',\n",
       " 'optimizer_name': 'SGD',\n",
       " 'learning_rate': 0.002352959348061621,\n",
       " 'batch_size': 50,\n",
       " 'weight_decay': 9.783797277120768e-05,\n",
       " 'p_dropout': 0.05615477543809351,\n",
       " 'early_stopping': True,\n",
       " 'epochs': 200,\n",
       " 'patience': 10,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e6b9200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                   | 0/200 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 265\u001b[0m, in \u001b[0;36mMLPBinaryClassifier.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train_standard\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 132\u001b[0m, in \u001b[0;36mMLPEstimatorSklearn.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    131\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batchX)\n\u001b[0;32m--> 132\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "model_mlp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fedc829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Set - Accuracy</th>\n",
       "      <td>0.979586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - Precision</th>\n",
       "      <td>0.980095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - Recall</th>\n",
       "      <td>0.979586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Set - F1</th>\n",
       "      <td>0.979169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Accuracy</th>\n",
       "      <td>0.980541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Precision</th>\n",
       "      <td>0.981003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Recall</th>\n",
       "      <td>0.980541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - F1</th>\n",
       "      <td>0.980163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Scores\n",
       "Train Set - Accuracy   0.979586\n",
       "Train Set - Precision  0.980095\n",
       "Train Set - Recall     0.979586\n",
       "Train Set - F1         0.979169\n",
       "Test Set - Accuracy    0.980541\n",
       "Test Set - Precision   0.981003\n",
       "Test Set - Recall      0.980541\n",
       "Test Set - F1          0.980163"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4212cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mlp.receiver_operating_characteristics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac53482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_test = df_spark.sample(fraction=0.05, seed=30)\n",
    "df_test = df_test.dropna(subset=['loan_status'])\n",
    "features_collected = df_test.select(features).collect()\n",
    "X_test = np.array([list(feature) for feature in features_collected])\n",
    "target_collected = df_test.select('loan_status').collect()\n",
    "y_test = np.array([feature['loan_status'] for feature in target_collected])\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09624bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Set - Accuracy</th>\n",
       "      <td>0.976740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Precision</th>\n",
       "      <td>0.977391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - Recall</th>\n",
       "      <td>0.976740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set - F1</th>\n",
       "      <td>0.976157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Scores\n",
       "Test Set - Accuracy   0.976740\n",
       "Test Set - Precision  0.977391\n",
       "Test Set - Recall     0.976740\n",
       "Test Set - F1         0.976157"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.model_performance_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13a3b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_value_collected = df_spark.limit(1).collect()[0]\n",
    "single_value = np.array([value for key, value in single_value_collected.asDict().items() if key != 'loan_status']).reshape(1,-1)\n",
    "single_value_target = np.array([value for key, value in single_value_collected.asDict().items() if key == 'loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7c7a098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.predict(single_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a02be47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funded_amnt_inv         4.944152e-09\n",
       "funded_amnt             4.629140e-09\n",
       "loan_amnt               1.646456e-09\n",
       "total_rec_int           2.905649e-10\n",
       "fico_range_high         2.280819e-11\n",
       "last_fico_range_low     1.245976e-11\n",
       "recoveries              0.000000e+00\n",
       "mths_since_rcnt_il      0.000000e+00\n",
       "mo_sin_old_rev_tl_op    0.000000e+00\n",
       "int_rate               -5.668992e-15\n",
       "last_credit_pull_d     -4.696943e-11\n",
       "last_fico_range_high   -8.651511e-11\n",
       "last_pymnt_amnt        -9.824349e-11\n",
       "total_pymnt            -3.772133e-09\n",
       "total_pymnt_inv        -4.536248e-09\n",
       "total_rec_prncp        -4.989309e-09\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=0.980, test=0.982) total time=  27.1s\n",
      "[CV 1/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=0.956, test=0.936) total time=   6.5s\n",
      "[CV 5/5] END activation_name=Tanh, alpha=0.21544346900318823, batch_size=50, hidden_layer_sizes=(100, 100), learning_rate=0.002352959348061621, optimizer_name=SGD, p_dropout=0.05615477543809351, weight_decay=9.783797277120768e-05;, score=(train=0.984, test=0.988) total time=  25.2s\n",
      "[CV 3/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=0.960, test=0.968) total time=   4.3s\n",
      "[CV 4/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=0.960, test=0.968) total time=   5.0s\n",
      "[CV 5/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=0.970, test=0.972) total time=  11.3s\n",
      "[CV 5/5] END activation_name=Leaky_relu, alpha=0.31622776601683794, batch_size=430, hidden_layer_sizes=(100, 50, 25), learning_rate=0.0001972606689184097, optimizer_name=SGD, p_dropout=0.26866163896885376, weight_decay=0.0011453530979564342;, score=(train=0.976, test=0.978) total time=   5.5s\n",
      "[CV 4/5] END activation_name=Sigmoid, alpha=0.03162277660168379, batch_size=80, hidden_layer_sizes=(100, 50), learning_rate=0.003584739875476995, optimizer_name=Adam, p_dropout=0.357842665401539, weight_decay=2.6620797194541587e-05;, score=(train=0.985, test=0.990) total time=  17.7s\n"
     ]
    }
   ],
   "source": [
    "model_mlp.compute_integrated_gradients(single_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cd18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
